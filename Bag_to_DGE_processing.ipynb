{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#**********Realsense bag file -> depth, grayscale, and edge*********\n",
    "# This notebook assumes several things, firstly that the bag files are recorded ~1-1.5m from the cow's back.\n",
    "# This is so that the thresholds used to find the cow in the frame can be hardcoded, if you find that there is too much/too little of the cow in frame,\n",
    "# they will have to be adjusted.\n",
    "\n",
    "# Next, the code assumes the following file architecture: working directory (that this notebook is in)\\dataset folder\\BCS class each bagfile belongs to\\bagfiles themselves\n",
    "# The output file architecture: dataset_folder_processed\\BCS_class\\frame_number_DGE.tif\n",
    "# The dataloader for the transformer assumes that each image is independent of each other image, so what cow each frame came from is irrelevent.\n",
    "# This leaves images belonging to the same class being mixed together.\n",
    "\n",
    "# Parameters for each operation are changed in the last cell of the notebook, with the defaults listed beside them\n",
    "\n",
    "# ****The class folders must be deleted between runs, as this code does not delete previous rundata, it just assigns images names based on the total number of\n",
    "# images in the class folder, so deleting images and then running the code again will not generate a fresh dataset, and will instead overwrite some images that have \n",
    "# conflicting names\n",
    "\n",
    "#Lastly, this expects all bag files to be 640x480 resolution, and filmed with NO postprocessing. FPS doesn't matter so long as the cow is actually cpatured at\n",
    "# some point, although 30 fps seems to be too much for the USB 2.0 cable to use, and it corrupts the resulting bagfile, 10-15 fps is recommended.\n",
    "\n",
    "import pyrealsense2.pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import os\n",
    "import datetime\n",
    "import skimage.filters\n",
    "import pandas as pd\n",
    "import glob\n",
    "import imageio\n",
    "\n",
    "# Change this to the directory containing the class folders and bag files\n",
    "bag_files_dir = 'BCS_classes_with_bag_files'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_preprocessing(depth_img, background):\n",
    "    # [:, int((848-640)/2):int(-(848-640)/2)]\n",
    "    depth_img = background - depth_img\n",
    "\n",
    "    otsu_thresh = skimage.filters.threshold_otsu(depth_img)\n",
    "    img_post = np.where(depth_img < otsu_thresh, depth_img, 0)\n",
    "\n",
    "    img_post = np.where(img_post > 600, depth_img, 0)\n",
    "\n",
    "    img_mask = np.where(img_post != 0, 1, 0)\n",
    "    img_seg = skimage.measure.label(img_mask, background=0, connectivity=2)\n",
    "    #assert( img_seg.max() != 0 )\n",
    "    if img_seg.max() != 0:\n",
    "        mask = img_seg == np.argmax(np.bincount(img_seg.flat)[1:])+1\n",
    "    else:\n",
    "        mask = np.zeros(np.shape(depth_img))\n",
    "\n",
    "    depth_img = np.where(mask != 0, depth_img, 0)\n",
    "    try:\n",
    "        depth_img = (depth_img/np.max(depth_img)*255).astype('uint8')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return depth_img, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifications to image preprocessing should be done here.\n",
    "\n",
    "def extract_tiff_from_bag(filename, thresh_lower, thresh_higher, pixel_thresh_top, pixel_thresh_lower, \n",
    "                        pixel_thresh_total_non_zero, spatial_mag, spatial_smooth_alpha, spatial_smooth_delta, \n",
    "                        spatial_hole_fill, temporal_smooth_alpha, temporal_smooth_delta, temporal_hole_fill):\n",
    "    BCS_class = os.path.dirname(filename)[-1]\n",
    "    parent_dir = os.path.basename(os.path.dirname(os.path.dirname(filename)))\n",
    "    num_pics_in_class = len(glob.glob(parent_dir+'_processed'+'\\\\'+BCS_class+'\\\\*'))\n",
    "    length = 480\n",
    "\n",
    "\n",
    "    try:\n",
    "        pipeline = rs.pipeline()\n",
    "        config = rs.config()\n",
    "        config.enable_device_from_file(filename, False)\n",
    "        pipeline.start(config)\n",
    "    except RuntimeError:\n",
    "        return\n",
    "\n",
    "\n",
    "    spatial = rs.spatial_filter()\n",
    "    spatial.set_option(rs.option.filter_magnitude, spatial_mag)\n",
    "    spatial.set_option(rs.option.filter_smooth_alpha, spatial_smooth_alpha)\n",
    "    spatial.set_option(rs.option.filter_smooth_delta, spatial_smooth_delta)\n",
    "    spatial.set_option(rs.option.holes_fill, spatial_hole_fill)\n",
    "\n",
    "    #this temporal filtering is added 1/25/22, so it might be the source of things breaking\n",
    "    temporal = rs.temporal_filter()\n",
    "    temporal.set_option(rs.option.filter_smooth_alpha, temporal_smooth_alpha)\n",
    "    temporal.set_option(rs.option.filter_smooth_delta, temporal_smooth_delta)\n",
    "    temporal.set_option(rs.option.holes_fill, temporal_hole_fill)\n",
    "\n",
    "    thresh = rs.threshold_filter(min_dist = thresh_lower, max_dist = thresh_higher)\n",
    "    \n",
    "    align_to = rs.stream.color\n",
    "    align = rs.align(align_to)\n",
    "\n",
    "\n",
    "    frames = pipeline.wait_for_frames()\n",
    "    depth_frame = frames.get_depth_frame()\n",
    "    color_frame = frames.get_color_frame()\n",
    "    color_image=np.asanyarray(color_frame.get_data())\n",
    "    thresh_frame = thresh.process(depth_frame)\n",
    "    spatial_depth = spatial.process(thresh_frame)\n",
    "    filtered_depth = temporal.process(spatial_depth)\n",
    "    background_image = np.asanyarray(filtered_depth.get_data())\n",
    "    if np.shape(background_image)[1] != np.shape(color_image)[1]:\n",
    "                    #print(np.shape(background_image)[1])\n",
    "                    #print(np.shape(color_image)[1])\n",
    "                    new_depth = np.zeros(np.shape(background_image[:, 104:-104]))\n",
    "                    #print(np.shape(new_depth)[1])\n",
    "                    new_depth=background_image[:, 104:-104]\n",
    "                    background_image=new_depth\n",
    "                    #print(np.shape(background_image)[1])\n",
    "\n",
    "\n",
    "    stop = True\n",
    "    while True:\n",
    "        try:\n",
    "            #getting frames from the camera\n",
    "            frames = pipeline.wait_for_frames(100)\n",
    "            depth_frame = frames.get_depth_frame()\n",
    "            color_frame = frames.get_color_frame()\n",
    "            thresh_frame = thresh.process(depth_frame)\n",
    "            spatial_depth = spatial.process(thresh_frame)\n",
    "            filtered_depth = temporal.process(spatial_depth)\n",
    "            depth_image = np.asanyarray(filtered_depth.get_data())\n",
    "            color_image = np.asanyarray(color_frame.get_data())\n",
    "\n",
    "            if np.shape(depth_image)[1] != np.shape(color_image)[1]:\n",
    "                    #print(np.shape(depth_image)[1])\n",
    "                    #print(np.shape(color_image)[1])\n",
    "                    new_depth = np.zeros(np.shape(depth_image[:, 104:-104]))\n",
    "                    #print(np.shape(new_depth)[1])\n",
    "                    new_depth=depth_image[:, 104:-104]\n",
    "                    depth_image=new_depth\n",
    "                    #print(np.shape(depth_image)[1])\n",
    "\n",
    "\n",
    "\n",
    "            cropped_depth, mask = image_preprocessing(depth_image, background_image)\n",
    "            upper_pixels = np.sum(np.where(cropped_depth[:100, :] != 0, 1, 0))\n",
    "            lower_pixels = np.sum(np.where(cropped_depth[length-20:length, :] != 0, 1, 0))\n",
    "            total_nonzero_pixels = np.sum(np.where(cropped_depth != 0, 1, 0))\n",
    "            if (lower_pixels < pixel_thresh_lower) and (upper_pixels > pixel_thresh_top) and (total_nonzero_pixels > pixel_thresh_total_non_zero):#was 15k and 14k\n",
    "                \n",
    "                cropped_depth = (cropped_depth/np.max(cropped_depth)*255).astype('uint8')\n",
    "\n",
    "                # Processing not done by pyrealsense functions can be done on the variables below.\n",
    "                \n",
    "                cropped_color = color_image\n",
    "                cropped_color[:, :, 0] = np.where(mask==True, color_image[:, :, 0], 0)\n",
    "                cropped_color[:, :, 1] = np.where(mask==True, color_image[:, :, 1], 0)\n",
    "                cropped_color[:, :, 2] = np.where(mask==True, color_image[:, :, 2], 0)\n",
    "\n",
    "                img_DGE = np.zeros(np.shape(cropped_color))\n",
    "                img_DGE[:, :, 0] = cropped_depth\n",
    "                img_DGE[:, :, 1] = skimage.color.rgb2gray(cropped_color)\n",
    "                mask_dilation = skimage.morphology.binary_dilation(mask, skimage.morphology.ball(4, dtype=bool)[::, ::, 0], out=None)\n",
    "                img_DGE[:, :, 2] = skimage.feature.canny(cropped_depth, sigma=1.0).astype('uint8')*255*mask_dilation\n",
    "\n",
    "                imageio.imwrite(parent_dir+'_processed\\\\'+str(BCS_class)+'\\\\'+f\"{num_pics_in_class}_DGE.tif\", img_DGE.astype('uint8'), 'TIFF')\n",
    "                num_pics_in_class+=1\n",
    "\n",
    "            time.sleep(0.01)\n",
    "            \n",
    "        except RuntimeError:\n",
    "            pipeline.stop()\n",
    "            stop = False\n",
    "            print(filename)\n",
    "            break\n",
    "    \n",
    "    if stop == True:\n",
    "        pipeline.stop()\n",
    "        print(filename)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "February_Data\\3\\Cow_8_2023.bag\n",
      "February_Data\\4\\Cow_10_0014.bag\n",
      "February_Data\\4\\Cow_11_0075.bag\n",
      "February_Data\\4\\Cow_2_6016.bag\n",
      "February_Data\\4\\Cow_3_6018.bag\n",
      "February_Data\\4\\Cow_5_8041.bag\n",
      "February_Data\\5\\Cow_12_6006.bag\n",
      "February_Data\\5\\Cow_13_8001.bag\n",
      "February_Data\\5\\Cow_14_1044.bag\n",
      "February_Data\\5\\Cow_4_8036.bag\n",
      "February_Data\\5\\Cow_6_5029.bag\n",
      "February_Data\\5\\Cow_7_6022.bag\n",
      "February_Data\\5\\Cow_9_NOTG.bag\n",
      "February_Data\\misc\\Background.bag\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zacha\\AppData\\Local\\Temp/ipykernel_12568/2815287608.py:20: RuntimeWarning: invalid value encountered in true_divide\n",
      "  depth_img = (depth_img/np.max(depth_img)*255).astype('uint8')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "February_Data\\misc\\Background2.bag\n",
      "February_Data\\misc\\shwelemia.bag failed\n",
      "The directory 'c:\\\\Users\\\\zacha\\\\Documents\\\\Precision Ranching Code\\\\February_Data_processed\\\\c' does not exist\n",
      "February_Data\\misc\\test.bag\n"
     ]
    }
   ],
   "source": [
    "filenames = glob.glob(bag_files_dir+'\\\\*\\\\*.bag')\n",
    "\n",
    "dest_dir = bag_files_dir+'_processed'\n",
    "try:\n",
    "    os.mkdir(dest_dir)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "for i in range(1, 10):\n",
    "    try:\n",
    "        os.mkdir(dest_dir+'\\\\'+str(i))\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "\n",
    "for bag_file in filenames:\n",
    "    try:\n",
    "        extract_tiff_from_bag(bag_file, \n",
    "                            thresh_lower = 0.1, #0.1\n",
    "                            thresh_higher = 3.0, #3.0\n",
    "                            pixel_thresh_top = 10000, #10000\n",
    "                            pixel_thresh_lower = 400, #400\n",
    "                            pixel_thresh_total_non_zero = 25000, #25000\n",
    "                            spatial_mag = 5, #5\n",
    "                            spatial_smooth_alpha = 0.5, #0.5\n",
    "                            spatial_smooth_delta = 20, #20\n",
    "                            spatial_hole_fill = 2, #2\n",
    "                            temporal_smooth_alpha = 0.15, #0.15\n",
    "                            temporal_smooth_delta = 50, #50\n",
    "                            temporal_hole_fill = 3, #3\n",
    "                            )\n",
    "        #print(filenames[i], 'done')\n",
    "    except Exception as e:\n",
    "        print(bag_file, 'failed')\n",
    "        print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b70492cf92a1f78fc18b7684d71bbc4f8886ffb7e78a5e47686b46a1a93e069b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
