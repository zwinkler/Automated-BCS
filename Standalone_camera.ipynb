{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import pyrealsense2.pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import os\n",
    "import datetime\n",
    "import skimage\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "# import mercury\n",
    "# import RPi.GPIO as GPIO\n",
    "# import multiprocessing as mp\n",
    "# GPIO.setwarnings(False)\n",
    "# GPIO.setmode(GPIO.BCM)\n",
    "# GPIO.setup(13, GPIO.IN)\n",
    "# from myFunctions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tag(power):\n",
    "    reader = mercury.Reader(\"tmr:///dev/ttyUSB0\", baudrate=115200)\n",
    "    reader.set_region(\"NA2\")\n",
    "    reader.set_read_plan([1], \"GEN2\", bank=[\"user\"], read_power=power)\n",
    "    tag = reader.read(timeout=500)\n",
    "    if len(tag)!=0:\n",
    "        tag = str(bytes.fromhex(reader.read()[0].epc.decode('utf-8')))\n",
    "        tag = tag[2:-1]\n",
    "    if len(tag) == 0:\n",
    "        tag = 'No_RFID'\n",
    "\n",
    "    return tag\n",
    "\n",
    "def image_preprocessing(depth_img, background):\n",
    "    depth_img = background - depth_img\n",
    "\n",
    "    otsu_thresh = skimage.filters.threshold_otsu(depth_img)\n",
    "    img_post = np.where(depth_img<otsu_thresh, depth_img, 0)\n",
    "\n",
    "    img_post = np.where(img_post>600, depth_img, 0)\n",
    "\n",
    "    img_mask = np.where(img_post != 0, 1, 0)\n",
    "    img_seg = skimage.measure.label(img_mask, background = 0, connectivity=2)\n",
    "    assert( img_seg.max() != 0 )\n",
    "    mask = img_seg == np.argmax(np.bincount(img_seg.flat)[1:])+1\n",
    "\n",
    "    depth_img = np.where(mask != 0, depth_img, 0)\n",
    "\n",
    "    return depth_img, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to resolve request. Request to enable_device_from_file(\"March_Data\\Cow_15_68.bag\") was invalid, Reason: Failed to create ros reader: Error opening file: March_Data\\Cow_15_68.bag",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13160/1981342195.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m#config.enable_stream(rs.stream.color, width, length, rs.format.bgr8, fps)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mpipe_profile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m#decimation = rs.decimation_filter()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Failed to resolve request. Request to enable_device_from_file(\"March_Data\\Cow_15_68.bag\") was invalid, Reason: Failed to create ros reader: Error opening file: March_Data\\Cow_15_68.bag"
     ]
    }
   ],
   "source": [
    "fps = 30\n",
    "width = 848\n",
    "length = 480\n",
    "total_pixels = width*length\n",
    "\n",
    "\n",
    "# Configure depth and color streams\n",
    "pipeline = rs.pipeline()\n",
    "config = rs.config()\n",
    "config.enable_device_from_file('March_Data\\\\Cow_15_68.bag')\n",
    "#config.enable_stream(rs.stream.depth, width, length, rs.format.z16, fps)\n",
    "#config.enable_stream(rs.stream.color, width, length, rs.format.bgr8, fps)\n",
    "\n",
    "pipe_profile = pipeline.start(config)\n",
    "\n",
    "#decimation = rs.decimation_filter()\n",
    "#decimation.set_option(rs.option.filter_magnitude, 2)\n",
    "\n",
    "spatial = rs.spatial_filter()\n",
    "spatial.set_option(rs.option.filter_magnitude, 5)\n",
    "spatial.set_option(rs.option.filter_smooth_alpha, 1)\n",
    "spatial.set_option(rs.option.filter_smooth_delta, 50)\n",
    "spatial.set_option(rs.option.holes_fill, 2)\n",
    "\n",
    "thresh = rs.threshold_filter(min_dist = 0.1, max_dist = 3.0)\n",
    "\n",
    "# depth_sensor = pipe_profile.get_device().first_depth_sensor()\n",
    "\n",
    "# depth_sensor.set_option(rs.option.enable_auto_exposure, True)\n",
    "\n",
    "#getting the background when the camera is first turned on\n",
    "frames = pipeline.wait_for_frames()\n",
    "depth_frame = frames.get_depth_frame()\n",
    "color_frame = frames.get_color_frame()\n",
    "thresh_frame = thresh.process(depth_frame)\n",
    "filtered_depth = spatial.process(thresh_frame)\n",
    "background_image = np.asanyarray(filtered_depth.get_data())\n",
    "print(np.shape(background_image))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "while True:\n",
    "\n",
    "    #getting frames from the camera\n",
    "    frames = pipeline.wait_for_frames()\n",
    "    depth_frame = frames.get_depth_frame()\n",
    "    color_frame = frames.get_color_frame()\n",
    "    thresh_frame = thresh.process(depth_frame)\n",
    "    filtered_depth = spatial.process(thresh_frame)\n",
    "    depth_image = np.asanyarray(filtered_depth.get_data())\n",
    "    color_image = np.asanyarray(color_frame.get_data())\n",
    "\n",
    "    #import imageio\n",
    "    #background_image = imageio.imread('masks\\\\feb_background.tif')\n",
    "    cropped_depth, mask = image_preprocessing(depth_image, background_image)\n",
    "    upper_pixels = np.sum(np.where(cropped_depth[:100, :] != 0, 1, 0))\n",
    "    lower_pixels = np.sum(np.where(cropped_depth[length-20:length, :] != 0, 1, 0))\n",
    "    total_nonzero_pixels = np.sum(np.where(cropped_depth != 0, 1, 0))\n",
    "    cv2.line(cropped_depth,(0,100),(848,100),(255,0,0),1)\n",
    "    cv2.line(cropped_depth,(0, length-20),(848, length-20),(255,0,0),1)\n",
    "    \n",
    "    cv2.putText(cropped_depth, 'Lower Pixel values: '+str(lower_pixels),(0,400), cv2.FONT_HERSHEY_SIMPLEX, 0.5,(255),2,cv2.LINE_AA)\n",
    "    cv2.putText(cropped_depth, 'Upper Pixel values: '+str(upper_pixels),(0,150), cv2.FONT_HERSHEY_SIMPLEX, 0.5,(255),2,cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow('cropped depth', cropped_depth)\n",
    "    cv2.waitKey(1)\n",
    "    #print(lower_pixels, upper_pixels, total_nonzero_pixels)\n",
    "\n",
    "    if (lower_pixels < 400) and (upper_pixels > 15000): # and (total_nonzero_pixels > 10000):\n",
    "\n",
    "        #cropped_depth = (cropped_depth/np.max(cropped_depth)*255).astype('uint8')\n",
    "\n",
    "        cropped_color = color_image\n",
    "        cropped_color[:, :, 0] = np.where(mask==True, color_image[:, :, 0], 0)\n",
    "        cropped_color[:, :, 1] = np.where(mask==True, color_image[:, :, 1], 0)\n",
    "        cropped_color[:, :, 2] = np.where(mask==True, color_image[:, :, 2], 0)\n",
    "\n",
    "        # them to be suitable for the ViT\n",
    "        # cropped_color = skimage.transform.resize(cropped_color, (224, 224, 3))\n",
    "        # cropped_depth = skimage.transform.resize(cropped_depth, (224, 224))\n",
    "\n",
    "        #Now convert depth/color images to DGE\n",
    "        img_DGE = np.zeros(np.shape(color_image))\n",
    "        img_DGE[:, :, 0] = cropped_depth\n",
    "        img_DGE[:, :, 1] = skimage.color.rgb2gray(cropped_color)\n",
    "        mask_dilation = skimage.morphology.binary_dilation(mask, skimage.morphology.ball(4, dtype=bool)[::, ::, 0], out=None)\n",
    "        img_DGE[:, :, 2] = skimage.feature.canny(cropped_depth, sigma=1.0).astype('uint8')*255*mask_dilation\n",
    "\n",
    "        cv2.imshow('cropped color', img_DGE)\n",
    "        cv2.waitKey(1)\n",
    "    #cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b70492cf92a1f78fc18b7684d71bbc4f8886ffb7e78a5e47686b46a1a93e069b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
