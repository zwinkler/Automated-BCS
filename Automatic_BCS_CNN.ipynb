{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG Transfer Learning for Solar Flare Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from PIL import Image as pil_image\n",
    "import imageio\n",
    "import tensorflow\n",
    "%matplotlib inline\n",
    "#plt.rcParams.update({'font.size': 32})\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_params(model):\n",
    "    total_params = 0 # initialize counter for total params\n",
    "    trainable_params = 0 # initialize counter for trainable params\n",
    "    print('Layer Name\\t\\tType\\t\\tFilter shape\\t\\t# Parameters\\tTrainable') # print column headings\n",
    "    for layer in model.layers: # loop over layers\n",
    "        lname = layer.name # grab layer name\n",
    "        ltype = type(layer).__name__ # grab layer type\n",
    "        ltype[ltype.find('/'):] # parse for only the last part of the string\n",
    "        if ltype=='Conv2D': # print for convolutional layers\n",
    "            weights = layer.get_weights()\n",
    "            print(lname+'\\t\\t'+ltype+'\\t\\t'+str(weights[0].shape)+'\\t\\t'+\\\n",
    "                  str(layer.count_params())+'\\t'+str(layer.trainable))\n",
    "            if layer.trainable:\n",
    "                trainable_params += layer.count_params()\n",
    "            total_params += layer.count_params() # update number of params\n",
    "        elif ltype=='MaxPooling2D': # print for max pool layers\n",
    "            weights = layer.get_weights()\n",
    "            print(lname+'\\t\\t'+ltype+'\\t---------------\\t\\t---')\n",
    "        elif ltype=='Flatten': # print for flatten layers\n",
    "            print(lname+'\\t\\t'+ltype+'\\t\\t---------------\\t\\t---')\n",
    "        elif ltype=='Dense': # print for dense layers\n",
    "            weights = layer.get_weights()\n",
    "            print(lname+'\\t\\t\\t'+ltype+'\\t\\t'+str(weights[0].shape)+'\\t\\t'+\\\n",
    "                  str(layer.count_params())+'\\t'+str(layer.trainable))\n",
    "            if layer.trainable:\n",
    "                trainable_params += layer.count_params()\n",
    "            total_params += layer.count_params() # update number of params\n",
    "        elif ltype=='Dropout': # print for dropout layers\n",
    "            print(lname+'\\t\\t'+ltype+'\\t\\t------------------\\t---')\n",
    "    print('---------------')\n",
    "    print('Total trainable parameters: '+str(trainable_params)) # print total params\n",
    "    print('Total untrainable parameters: '+str(total_params-trainable_params))\n",
    "    print('Total parameters: '+str(total_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_shapes(model):\n",
    "    print('Layer Name\\t\\tType\\t\\tInput Shape\\t\\tOutput Shape\\tTrainable')# print column headings\n",
    "    for layer in model.layers:  # loop over layers\n",
    "        lname = layer.name # grab layer name\n",
    "        ltype = type(layer).__name__ # grab layer type\n",
    "        ltype[ltype.find('/'):] # parse for only the last part of the string\n",
    "        if ltype=='Conv2D': # print for convolutional layers\n",
    "            print(lname+'\\t\\t'+ltype+'\\t\\t'+str(layer.input_shape)+'\\t'+\\\n",
    "                  str(layer.output_shape)+'\\t'+str(layer.trainable))\n",
    "        elif ltype=='MaxPooling2D': # print for maxpool layers\n",
    "            print(lname+'\\t\\t'+ltype+'\\t'+str(layer.input_shape)+'\\t'+\\\n",
    "                  str(layer.output_shape))\n",
    "        elif ltype=='Flatten': # print for flatten layers\n",
    "            print(lname+'\\t\\t'+ltype+'\\t\\t'+str(layer.input_shape)+'\\t'+\\\n",
    "                  str(layer.output_shape))\n",
    "        elif ltype=='Dense': # print for dense layers\n",
    "            print(lname+'\\t\\t\\t'+ltype+'\\t\\t'+str(layer.input_shape)+'\\t\\t'+\\\n",
    "                  str(layer.output_shape)+'\\t'+str(layer.trainable))\n",
    "        elif ltype=='Dropout': # print for dropout layers\n",
    "            print(lname+'\\t\\t'+ltype+'\\t\\t'+str(layer.input_shape)+'\\t'+\\\n",
    "                  str(layer.output_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import preprocess_input\n",
    "from astropy.io import fits\n",
    "import skimage.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Input\n",
    "input_tensor = Input(shape=(224,224,3))\n",
    "model1 = keras.applications.vgg16.VGG16(include_top=False,weights='imagenet',input_tensor=input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "new_output = model1.output # take the output as currently defined\n",
    "new_output = Flatten()(new_output)\n",
    "#new_output = Dropout(0.5)(new_output)\n",
    "new_output = Dense(256,activation='relu')(new_output)\n",
    "new_output = Dropout(0.5)(new_output)\n",
    "new_output = Dense(256,activation='relu')(new_output)\n",
    "new_output = Dropout(0.5)(new_output)\n",
    "new_output = Dense(5,activation='softmax')(new_output) # operate on that output with another dense layer\n",
    "model2= Model(inputs=model1.input,outputs=new_output) # define a new model with the new output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer Name\t\tType\t\tFilter shape\t\t# Parameters\tTrainable\n",
      "block1_conv1\t\tConv2D\t\t(3, 3, 3, 64)\t\t1792\tTrue\n",
      "block1_conv2\t\tConv2D\t\t(3, 3, 64, 64)\t\t36928\tTrue\n",
      "block1_pool\t\tMaxPooling2D\t---------------\t\t---\n",
      "block2_conv1\t\tConv2D\t\t(3, 3, 64, 128)\t\t73856\tTrue\n",
      "block2_conv2\t\tConv2D\t\t(3, 3, 128, 128)\t\t147584\tTrue\n",
      "block2_pool\t\tMaxPooling2D\t---------------\t\t---\n",
      "block3_conv1\t\tConv2D\t\t(3, 3, 128, 256)\t\t295168\tTrue\n",
      "block3_conv2\t\tConv2D\t\t(3, 3, 256, 256)\t\t590080\tTrue\n",
      "block3_conv3\t\tConv2D\t\t(3, 3, 256, 256)\t\t590080\tTrue\n",
      "block3_pool\t\tMaxPooling2D\t---------------\t\t---\n",
      "block4_conv1\t\tConv2D\t\t(3, 3, 256, 512)\t\t1180160\tTrue\n",
      "block4_conv2\t\tConv2D\t\t(3, 3, 512, 512)\t\t2359808\tTrue\n",
      "block4_conv3\t\tConv2D\t\t(3, 3, 512, 512)\t\t2359808\tTrue\n",
      "block4_pool\t\tMaxPooling2D\t---------------\t\t---\n",
      "block5_conv1\t\tConv2D\t\t(3, 3, 512, 512)\t\t2359808\tTrue\n",
      "block5_conv2\t\tConv2D\t\t(3, 3, 512, 512)\t\t2359808\tTrue\n",
      "block5_conv3\t\tConv2D\t\t(3, 3, 512, 512)\t\t2359808\tTrue\n",
      "block5_pool\t\tMaxPooling2D\t---------------\t\t---\n",
      "flatten_1\t\tFlatten\t\t---------------\t\t---\n",
      "dense_3\t\t\tDense\t\t(25088, 256)\t\t6422784\tTrue\n",
      "dropout_2\t\tDropout\t\t------------------\t---\n",
      "dense_4\t\t\tDense\t\t(256, 256)\t\t65792\tTrue\n",
      "dropout_3\t\tDropout\t\t------------------\t---\n",
      "dense_5\t\t\tDense\t\t(256, 5)\t\t1285\tTrue\n",
      "---------------\n",
      "Total trainable parameters: 21204549\n",
      "Total untrainable parameters: 0\n",
      "Total parameters: 21204549\n"
     ]
    }
   ],
   "source": [
    "print_params(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model2.layers[:-3]:\n",
    "    layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer Name\t\tType\t\tFilter shape\t\t# Parameters\tTrainable\n",
      "block1_conv1\t\tConv2D\t\t(3, 3, 3, 64)\t\t1792\tFalse\n",
      "block1_conv2\t\tConv2D\t\t(3, 3, 64, 64)\t\t36928\tFalse\n",
      "block1_pool\t\tMaxPooling2D\t---------------\t\t---\n",
      "block2_conv1\t\tConv2D\t\t(3, 3, 64, 128)\t\t73856\tFalse\n",
      "block2_conv2\t\tConv2D\t\t(3, 3, 128, 128)\t\t147584\tFalse\n",
      "block2_pool\t\tMaxPooling2D\t---------------\t\t---\n",
      "block3_conv1\t\tConv2D\t\t(3, 3, 128, 256)\t\t295168\tFalse\n",
      "block3_conv2\t\tConv2D\t\t(3, 3, 256, 256)\t\t590080\tFalse\n",
      "block3_conv3\t\tConv2D\t\t(3, 3, 256, 256)\t\t590080\tFalse\n",
      "block3_pool\t\tMaxPooling2D\t---------------\t\t---\n",
      "block4_conv1\t\tConv2D\t\t(3, 3, 256, 512)\t\t1180160\tFalse\n",
      "block4_conv2\t\tConv2D\t\t(3, 3, 512, 512)\t\t2359808\tFalse\n",
      "block4_conv3\t\tConv2D\t\t(3, 3, 512, 512)\t\t2359808\tFalse\n",
      "block4_pool\t\tMaxPooling2D\t---------------\t\t---\n",
      "block5_conv1\t\tConv2D\t\t(3, 3, 512, 512)\t\t2359808\tFalse\n",
      "block5_conv2\t\tConv2D\t\t(3, 3, 512, 512)\t\t2359808\tFalse\n",
      "block5_conv3\t\tConv2D\t\t(3, 3, 512, 512)\t\t2359808\tFalse\n",
      "block5_pool\t\tMaxPooling2D\t---------------\t\t---\n",
      "flatten_1\t\tFlatten\t\t---------------\t\t---\n",
      "dense_3\t\t\tDense\t\t(25088, 256)\t\t6422784\tFalse\n",
      "dropout_2\t\tDropout\t\t------------------\t---\n",
      "dense_4\t\t\tDense\t\t(256, 256)\t\t65792\tTrue\n",
      "dropout_3\t\tDropout\t\t------------------\t---\n",
      "dense_5\t\t\tDense\t\t(256, 5)\t\t1285\tTrue\n",
      "---------------\n",
      "Total trainable parameters: 67077\n",
      "Total untrainable parameters: 21137472\n",
      "Total parameters: 21204549\n"
     ]
    }
   ],
   "source": [
    "print_params(model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Data Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approach taken from https://medium.com/analytics-vidhya/write-your-own-custom-data-generator-for-tensorflow-keras-1252b64e41c3\n",
    "\n",
    "From https://www.tensorflow.org/api_docs/python/tf/keras/utils/Sequence: \"Sequence are a safer way to do multiprocessing. This structure guarantees that the network will only train once on each sample per epoch which is not the case with generators.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "from astropy.io import fits\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import skimage.transform\n",
    "class FitsDataGen(Sequence):\n",
    "    # The input to the data generator will be the dataframe and which columns to use\n",
    "    def __init__(self, df, X_col, y_col,\n",
    "                 directory,\n",
    "                 batch_size,\n",
    "                 input_size=(224, 224, 3),\n",
    "                 target_size=None,\n",
    "                 bitdepth=None,\n",
    "                 shuffle=True):\n",
    "        \n",
    "        self.df = df.copy() # dataframe\n",
    "        self.X_col = X_col # column for X data (filename)\n",
    "        self.y_col = y_col # column for y data (class label)\n",
    "        self.directory = directory # base directory for data\n",
    "        self.batch_size = batch_size # batch size\n",
    "        self.input_size = input_size # size expected by network (224,224,3) for VGG\n",
    "        self.target_size = target_size # resized image for spatial res sims\n",
    "        self.bitdepth = bitdepth # quantized image for bitdepth sims\n",
    "        self.shuffle = shuffle # whether to shuffle batches\n",
    "        \n",
    "        self.n = len(self.df) # number of data points\n",
    "        self.nclasses = df[y_col].nunique() # number of classes\n",
    "            \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            self.df = self.df.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    def __get_input(self, path, directory, input_size, target_size, bitdepth):\n",
    "    \n",
    "        with fits.open(directory+path) as img: # read in fits image\n",
    "            img.verify('silentfix')\n",
    "            img = img[0].data\n",
    "            \n",
    "        #img = np.expand_dims(img,axis=2) # copy single channel to three to create rgb dimensioned image\n",
    "        #img = np.tile(img,(1,1,3))\n",
    "        \n",
    "        # scale to target_size\n",
    "        if target_size is not None:\n",
    "            img = skimage.transform.resize(img, (target_size[0],target_size[1]), order=1, mode='reflect',\\\n",
    "                                           clip=True, preserve_range=True, anti_aliasing=True)\n",
    "        \n",
    "        # scale to input_size (expected dimensions for input to network)\n",
    "        img = skimage.transform.resize(img, (input_size[0],input_size[1]), order=1, mode='reflect',\\\n",
    "                                       clip=True, preserve_range=True, anti_aliasing=True)\n",
    "        \n",
    "        # put bitdepth stuff here eventually\n",
    "        \n",
    "        # scale intensities to range [0,255] as expected by VGG preprocessing function\n",
    "        # can cheat a bit here and treat each channel the same since these are grayscale images\n",
    "        # img = img + 5978.7 # -5978.7 is minimum of entire magnetogram dataset\n",
    "        # img = img/(2*5978.7)*255 # +5978.7 is maximum of entire magnetogram dataset\n",
    "        # img[img<-2550] = -2550\n",
    "        # img = img + 2550 # -5978.7 is minimum of entire magnetogram dataset\n",
    "        # img = img/(5100)*255 # +5978.7 is maximum of entire magnetogram dataset\n",
    "        img = img/(3500)*255 #changed to 3500 because some pixels need clipping\n",
    "        img[img>255] = 255\n",
    "        \n",
    "        \n",
    "        \n",
    "        img = preprocess_input(img) # preprocess according to VGG expectations\n",
    "\n",
    "        return img\n",
    "    \n",
    "    \n",
    "    def __get_output(self, label, num_classes):\n",
    "        #print(label)\n",
    "        print(label, num_classes)\n",
    "        return tensorflow.keras.utils.to_categorical(label, num_classes=num_classes)\n",
    "    \n",
    "    def __get_data(self, batches):\n",
    "        # Generates data containing batch_size samples\n",
    "\n",
    "        path_batch = batches[self.X_col]\n",
    "        \n",
    "        label_batch = batches[self.y_col]\n",
    "\n",
    "        X_batch = np.asarray([self.__get_input(x, self.directory, self.input_size, self.target_size, self.bitdepth)\\\n",
    "                              for x in path_batch])\n",
    "\n",
    "        y_batch = np.asarray([self.__get_output(y, self.nclasses) for y in label_batch])\n",
    "        print(y_batch)\n",
    "        \n",
    "        return X_batch, y_batch\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        batches = self.df[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        X, y = self.__get_data(batches)        \n",
    "        return X, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n // self.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = pd.read_csv('train_data.csv',dtype=str)\n",
    "# val_df = pd.read_csv('val_data.csv',dtype=str)\n",
    "# test_df = pd.read_csv('test_data.csv',dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = train_df.sample(frac=1).reset_index(drop=True)\n",
    "# val_df = val_df.sample(frac=1).reset_index(drop=True)\n",
    "# test_df = test_df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_generator = FitsDataGen(train_df, X_col='filename', y_col='class', directory='',\\\n",
    "#                               batch_size=128, input_size=(224,224,3),\\\n",
    "#                            target_size=None, bitdepth=None, shuffle=True)\n",
    "# val_generator = FitsDataGen(val_df, X_col='filename', y_col='class', directory='',\\\n",
    "#                             batch_size=128, input_size=(224,224,3),\\\n",
    "#                            target_size=None, bitdepth=None, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train_df = pd.read_csv('classifier_VGG/Train_Data_by_AR_sr600x600.csv',dtype=str)\n",
    "# val_df = pd.read_csv('classifier_VGG/Validation_data_by_AR_sr600x600.csv',dtype=str)\n",
    "# test_df = pd.read_csv('classifier_VGG/Test_Data_by_AR_sr600x600.csv',dtype=str)\n",
    "\n",
    "train_df = pd.read_csv('train_data.csv',dtype=str)\n",
    "val_df = pd.read_csv('val_data.csv',dtype=str)\n",
    "test_df = pd.read_csv('test_data.csv',dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4249 validated image filenames belonging to 5 classes.\n",
      "Found 529 validated image filenames belonging to 5 classes.\n",
      "Found 4249 validated image filenames belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.vgg16 import decode_predictions\n",
    "\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "train_generator = train_datagen.flow_from_dataframe(dataframe=train_df,\\\n",
    "                                                    directory='',\\\n",
    "                                                    xcol='filename',y_col='class',\\\n",
    "                                                    target_size=(224,224), color_mode='rgb',\\\n",
    "                                                    batch_size=128, class_mode='categorical',\\\n",
    "                                                    shuffle=True)\n",
    "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "val_generator = val_datagen.flow_from_dataframe(dataframe=val_df,\\\n",
    "                                                directory = '',\\\n",
    "                                                xcol='filename',ycol='class',\\\n",
    "                                                target_size=(224,224), color_mode='rgb',\\\n",
    "                                                batch_size=128, class_mode='categorical',\\\n",
    "                                                shuffle=True)\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "test_generator = test_datagen.flow_from_dataframe(dataframe=test_df,\\\n",
    "                                                directory = '',\\\n",
    "                                                xcol='filename',ycol='class',\\\n",
    "                                                target_size=(224,224), color_mode='rgb',\\\n",
    "                                                batch_size=128, class_mode='categorical',\\\n",
    "                                                shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "# from keras.applications.vgg16 import preprocess_input\n",
    "# from keras.applications.vgg16 import decode_predictions\n",
    "# train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "# train_generator = train_datagen.flow_from_directory('BCS_sorted_HDV\\\\',\\\n",
    "#                                                     target_size=(224,224), color_mode='rgb',\\\n",
    "#                                                     batch_size=128, class_mode='categorical',\\\n",
    "#                                                     shuffle=True)\n",
    "# val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "# val_generator = val_datagen.flow_from_directory('BCS_sorted_HDV\\\\',\\\n",
    "#                                                     target_size=(224,224), color_mode='rgb',\\\n",
    "#                                                     batch_size=128, class_mode='categorical',\\\n",
    "#                                                     shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_tnr(y_true,y_pred):\n",
    "    import keras.backend as K\n",
    "    y_true = K.argmax(y_true)\n",
    "    y_pred = K.argmax(y_pred)\n",
    "    neg_y_true = 1 - y_true\n",
    "    neg_y_pred = 1 - y_pred\n",
    "    fp = K.cast(K.sum(neg_y_true * y_pred),'float32')\n",
    "    tn = K.cast(K.sum(neg_y_true * neg_y_pred),'float32')\n",
    "    tnr = tn / (tn + fp + K.epsilon())\n",
    "    return tnr\n",
    "\n",
    "def categorical_tpr(y_true,y_pred):\n",
    "    import keras.backend as K\n",
    "    y_true = K.argmax(y_true)\n",
    "    y_pred = K.argmax(y_pred)\n",
    "    neg_y_pred = 1 - y_pred\n",
    "    fn = K.cast(K.sum(y_true * neg_y_pred),'float32')\n",
    "    tp = K.cast(K.sum(y_true * y_pred),'float32')\n",
    "    tpr = tp / (tp + fn + K.epsilon())\n",
    "    return tpr\n",
    "\n",
    "def categorical_tss(y_true,y_pred):\n",
    "    import keras.backend as K\n",
    "    tpr = categorical_tpr(y_true,y_pred)\n",
    "    tnr = categorical_tnr(y_true,y_pred)\n",
    "    tss = tpr + tnr - 1\n",
    "    return tss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "adam_opt = Adam(learning_rate=0.001)\n",
    "model2.compile(loss='categorical_crossentropy', optimizer=adam_opt,\\\n",
    "               metrics=['categorical_accuracy',categorical_tnr,categorical_tpr,categorical_tss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.0\n",
      "Batch size:  128\n",
      "5.0\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "filepath = 'BCS_CNN\\\\BCS_CNN.hdf5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_categorical_tss', verbose=1, save_best_only=False, mode='max')\n",
    "early_stop = EarlyStopping(monitor='val_categorical_tss', min_delta=0.001, patience=5, verbose=1, mode='max')\n",
    "#callbacks_list = [checkpoint, early_stop]\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "step_size_train = np.ceil(train_generator.n/train_generator.batch_size)\n",
    "print(step_size_train)\n",
    "print('Batch size: ', train_generator.batch_size)\n",
    "#step_size_train = 2373 # to help debug val accuracy issue\n",
    "step_size_val = np.ceil(val_generator.n/val_generator.batch_size)\n",
    "print(step_size_val)\n",
    "#step_size_val = 303 # to help debug val accuracy issue\n",
    "\n",
    "# the following assumes that 0 is the majority class\n",
    "# class_weights = {0: 1.,\n",
    "#                  1: (np.asarray(train_generator.classes)==0).sum()/(np.asarray(train_generator.classes)==1).sum()}\n",
    "# the following taken from https://www.tensorflow.org/tutorials/structured_data/imbalanced_data\n",
    "#class_weights = {0: (1/(train_generator.classes==0).sum())*len(train_generator.classes)/2,\n",
    "#                 1: (1/(train_generator.classes==1).sum())*len(train_generator.classes)/2}\n",
    "# class_weights = {0: 1.,\n",
    "#                 1: 6.}\n",
    "\n",
    "from sklearn.utils import class_weight \n",
    "class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(train_df['class']), y =train_df['class'])\n",
    "class_weights = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1.4163333333333334, 1: 1.4258389261744966, 2: 0.4291919191919192, 3: 0.9040425531914894, 4: 6.389473684210526}\n"
     ]
    }
   ],
   "source": [
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.2725 - categorical_accuracy: 0.8706 - categorical_tnr: -1.9486 - categorical_tpr: 2.3588 - categorical_tss: -0.5898\n",
      "Epoch 00001: saving model to BCS_CNN\\BCS_CNN.hdf5\n",
      "34/34 [==============================] - 9s 265ms/step - loss: 0.2725 - categorical_accuracy: 0.8706 - categorical_tnr: -1.9486 - categorical_tpr: 2.3588 - categorical_tss: -0.5898 - val_loss: 0.1142 - val_categorical_accuracy: 0.9830 - val_categorical_tnr: -2.0823 - val_categorical_tpr: 2.4089 - val_categorical_tss: -0.6734\n",
      "Epoch 2/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.3128 - categorical_accuracy: 0.8651 - categorical_tnr: -1.9337 - categorical_tpr: 2.3481 - categorical_tss: -0.5856\n",
      "Epoch 00002: saving model to BCS_CNN\\BCS_CNN.hdf5\n",
      "34/34 [==============================] - 9s 270ms/step - loss: 0.3128 - categorical_accuracy: 0.8651 - categorical_tnr: -1.9337 - categorical_tpr: 2.3481 - categorical_tss: -0.5856 - val_loss: 0.1097 - val_categorical_accuracy: 0.9924 - val_categorical_tnr: -2.0344 - val_categorical_tpr: 2.3969 - val_categorical_tss: -0.6375\n",
      "Epoch 3/10\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.3013 - categorical_accuracy: 0.8659 - categorical_tnr: -1.9584 - categorical_tpr: 2.3625 - categorical_tss: -0.5959\n",
      "Epoch 00003: saving model to BCS_CNN\\BCS_CNN.hdf5\n",
      "34/34 [==============================] - 9s 269ms/step - loss: 0.3013 - categorical_accuracy: 0.8659 - categorical_tnr: -1.9584 - categorical_tpr: 2.3625 - categorical_tss: -0.5959 - val_loss: 0.1373 - val_categorical_accuracy: 0.9868 - val_categorical_tnr: -2.0689 - val_categorical_tpr: 2.4545 - val_categorical_tss: -0.6144\n",
      "Epoch 4/10\n",
      " 2/34 [>.............................] - ETA: 7s - loss: 0.2761 - categorical_accuracy: 0.8711 - categorical_tnr: -1.8778 - categorical_tpr: 2.2215 - categorical_tss: -0.6563 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-fc46f5c9dfba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m history = model2.fit(train_generator, steps_per_epoch=step_size_train, epochs=10, verbose=1,\\\n\u001b[0m\u001b[0;32m      2\u001b[0m                      \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep_size_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                      validation_freq=1, class_weight=class_weights)\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML_env\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1214\u001b[0m                 _r=1):\n\u001b[0;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1217\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML_env\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML_env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 910\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML_env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    940\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 942\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    943\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML_env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3128\u001b[0m       (graph_function,\n\u001b[0;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3130\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML_env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1958\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1959\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML_env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML_env\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model2.fit(train_generator, steps_per_epoch=step_size_train, epochs=10, verbose=1,\\\n",
    "                     callbacks=callbacks_list, validation_data=val_generator, validation_steps=step_size_val,\\\n",
    "                     validation_freq=1, class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_Xtrain(X_train):\n",
    "    mn = []\n",
    "    mx = []\n",
    "    Xn_train = np.zeros(np.shape(X_train))\n",
    "    X_norm = np.zeros(np.shape(X_train))\n",
    "    for i in range(len(X_train[0, ::])):\n",
    "        mn.append(np.min(X_train[::, i]))\n",
    "        Xn_train[::, i] = X_train[::, i] - mn[i]\n",
    "    for i in range(len(X_train[0, ::])):\n",
    "        mx.append(np.max(Xn_train[::, i]))\n",
    "        if mx[i] == 0:\n",
    "            X_norm[::, i] = 0\n",
    "        if mx[i] != 0:\n",
    "            X_norm[::, i] = Xn_train[::, i]/mx[i]\n",
    "            \n",
    "    return X_norm, mx, mn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the network model3 is:  0.1148505530713109\n",
      "dict_keys(['loss', 'categorical_accuracy', 'categorical_tnr', 'categorical_tpr', 'categorical_tss', 'val_loss', 'val_categorical_accuracy', 'val_categorical_tnr', 'val_categorical_tpr', 'val_categorical_tss'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x21bb3bdceb0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAJOCAYAAABROcYpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAbaElEQVR4nO3de7Dnd13f8debbGJCLoZLhECAaEdpHUaIszIFlCp4AUG0M1bwgsrYZjoqhZEWwTJSrNqxUynaUWciIAgIclVuAmmVUbxANhjUEEQmwGRJMBfAECjk9u4fv9/Sk2Wz+9uzv5Pfnvc+HjNnsuf3+/6+v/d+d5PzPJ/v93tS3R0AgKnutukBAAB2ktgBAEYTOwDAaGIHABhN7AAAo4kdAGA0sQPHsao6rareUlX/VFWvO4b9/HBVvWuds21CVf1RVf3YNl/7i1V1fVV9ct1zrUtVfWtV7V9x2/9SVa/c6ZlgArEDa1BVP1RV+6rqpqq6ZvlF+ZvXsOvvT3KfJPfq7n+z3Z1096u6+zvXMM8dLL84d1W98aDHH7p8/N0r7melL9zd/fjufvk25nxAkmcl+fruvu/Rvv5O9tlV9Y9VtWfLY3uq6tqqukt/gFlVfV1V/WFVXVdVn6qqd1bVg+/KGeB4JnbgGFXVzyR5UZJfziJMHpjkN5N87xp2/6AkH+7uW9ewr51yXZJHVtW9tjz2Y0k+vK43qIVj+e/Vg5Lc0N3XbuO99xzm6c8kefyWz787yaeP9j3W4Owkb07y4Cz+Dr4vyR9uYA44LokdOAZV9ZVJfiHJT3X3G7v7c919S3e/pbv/03Kbr6iqF1XV1cuPF1XVVyyf+9aq2l9Vz1quCFxTVU9bPveCJD+f5MnLFaOfOHgFpKrOX64w7Fl+/uNVdWVVfbaqPlpVP7zl8fdsed0jq+qS5emxS6rqkVuee3dV/deq+vPlft5VVfc+zGG4OckfJHnK8vUnJfmBJK866Fj9WlVdVVU3VtWlVfUty8cfl+Tntvw+P7Bljl+qqj9P8vkkX7N87N8un/+tqnr9lv3/SlX9n6qqg97325NcnOR+y/2/bPn4k6rq8qr6zHK//2LLaz5WVT9bVX+T5HOHCZ5XJPnRLZ//aJLfPej971dVb16uuHykqv7dludOq6qXVdWnq+qDSb7pEK99w3LF5qNV9R8ONUR3v6+7X9Ldn+ruW5L8zyQPPihA4YQlduDYPCLJqUnedJht/nOSf5nkYUkemuThSZ635fn7JvnKJPdP8hNJfqOq7tHdz89itej3u/uM7n7J4QapqtOT/HqSx3f3mUkemeSyQ2x3zyRvW257ryQvTPK2g74w/lCSpyX5qiSnJPmPh3vvLL7AH/ii/11JLk9y9UHbXJLFMbhnkt9L8rqqOrW733HQ7/OhW17z1CQXJjkzyccP2t+zknzDMuS+JYtj92N90P8Dp7v/dxarL1cv9//jVfV1SV6d5JlJzkny9iRvqapTtrz0B5M8IcnZh1lZ+4Mkj66qs6vq7CTfki9fUXl1kv1J7pfFaclfrqrHLp97fpJ/tvz4rixWxJIky5WstyT5QBZ/Nx6b5JlV9V13MstWj07yye6+YYVtYTyxA8fmXkmuP8Jpph9O8gvdfW13X5fkBVl8ET/gluXzt3T325PclMXpiO24PclDquq07r6muy8/xDZPSPIP3f2K7r61u1+d5ENJvmfLNr/T3R/u7v+b5LVZRMqd6u6/SHLP5XUiX7a6sdzmld19w/I9fzXJV+TIv8+Xdffly9fcctD+Pp/kR7KItVcmeXp3r3Rxb5InJ3lbd1+83O//SHJaFoF4wK9391XLY3BnvpBFkDw5i5WtNy8fS/Kla4W+OcnPdvcXuvuyJC/O///z/4Ekv7RckbkqiwA94JuSnNPdv9DdN3f3lUl+e/k+d6qqzkvyG0l+5rBHAE4gYgeOzQ1J7n2E6zrulzuuSnx8+diX9nFQLH0+yRlHO0h3fy6LL7r/Psk1VfW2qvrnK8xzYKb7b/l86x1Lq87ziiQ/neTbcoiVruWpuiuWp84+k8Vq1uFOjyXJVYd7srvfl+TKJJVFlK3qDsegu29fvtfWY3DY997iwKrWoSLvfkk+1d2f3fLY1mN9v4PeZ+ufy4OyOPX2mQMfWZzuu8+dDVJV5yR5V5LfXEYsELEDx+ovs/hO/vsOs83VWXzhOuCB+fJTPKv6XJK7b/n8DncWdfc7u/s7kpybxWrNb68wz4GZPrHNmQ54RZKfTPL25arLlyxPM/1sFisZ9+jus5P8UxaRkiR3dvfSYe9qqqqfymKF6Ookzz6KWe9wDJbX+TwgdzwGq95R9WdZHO/7JHnPQc9dncWK15lbHtt6rK9Zvu/W5w64KslHu/vsLR9ndvd3H2qIqrpHFqHz5u7+pRVnhxOC2IFj0N3/lMVFxL9RVd9XVXevqpOr6vFV9d+Xm706yfOq6pzlhb4/n8Vpl+24LItrRB5Yi4ujn3vgiaq6z/Ki29OTfDGL02G3HWIfb0/ydbW4XX5PVT05ydcnees2Z0qSdPdHk/yrLK5ROtiZSW7N4s6tPVX180nO2vL8PyY5v47ijqvldTe/mMWprKcmeXZVPWzFl782yROq6rFVdXIW1/98MclfrPr+ByyvEfqeJE86xPVCVy33+d+q6tSq+oYsri06cPH2a5M8t6rusTz99PQtL39fkhuXF0qfVlUnVdVDquoOFzEnSVWdleSdSf68u59ztL8HmE7swDHq7hdmcX3E87L4Yn5VFqdz/mC5yS8m2Zfkb5L8bZL3Lx/bzntdnOT3l/u6NHcMlLtl8UX76iSfyiI8fvIQ+7ghyROX296QxYrIE7v7+u3MdNC+39Pdh1q1emeSP8ridvSPZ7EatvX0zYEfmHhDVb3/SO+zPG34yiS/0t0f6O5/yOIUzytqeafbEeb8+ywi6X8luT6LWPme7r75SK+9k/1dfifXRyWLC53Pz+LP5U1Jnr/8c0wW1299PMlHs1iVecWWfd62nOthy+evz+J6n688xHv86yyu8Xna8o6zAx8PPMS2cMKpg74RAQAYxcoOADCa2AEARhM7AMBoYgcAGO1wPwht2+ou/j/+AgB0dx3qcSs7AMBoYgcAGE3sAACjiR0AYDSxAwCMJnYAgNHEDgAwmtgBAEYTOwDAaGIHABhN7AAAo4kdAGA0sQMAjCZ2AIDRxA4AMJrYAQBGEzsAwGhiBwAYTewAAKOJHQBgNLEDAIwmdgCA0cQOADCa2AEARhM7AMBoYgcAGE3sAACjiR0AYDSxAwCMJnYAgNHEDgAwmtgBAEYTOwDAaGIHABhN7AAAo60UO1X1uKr6+6r6SFU9Z6eHAgBYl+ruw29QdVKSDyf5jiT7k1yS5Ae7+4OHec3hdwoAsGbdXYd6fJWVnYcn+Uh3X9ndNyd5TZLvXedwAAA7ZZXYuX+Sq7Z8vn/52B1U1YVVta+q9q1rOACAY7VnhW0OtST0ZaepuvuiJBclTmMBAMePVVZ29id5wJbPz0ty9c6MAwCwXqvEziVJvraqvrqqTknylCRv3tmxAADW44insbr71qr66STvTHJSkpd29+U7PhkAwBoc8dbzbe3UNTsAwF3sWG49BwDYtcQOADCa2AEARhM7AMBoYgcAGE3sAACjiR0AYDSxAwCMJnYAgNHEDgAwmtgBAEYTOwDAaGIHABhN7AAAo4kdAGA0sQMAjCZ2AIDRxA4AMJrYAQBGEzsAwGhiBwAYTewAAKOJHQBgNLEDAIwmdgCA0cQOADCa2AEARhM7AMBoYgcAGE3sAACjiR0AYDSxAwCMJnYAgNHEDgAwmtgBAEYTOwDAaGIHABhN7AAAo4kdAGA0sQMAjCZ2AIDRxA4AMJrYAQBGEzsAwGhiBwAYTewAAKOJHQBgNLEDAIwmdgCA0cQOADCa2AEARhM7AMBoYgcAGE3sAACjiR0AYDSxAwCMJnYAgNHEDgAwmtgBAEYTOwDAaGIHABhN7AAAo4kdAGA0sQMAjCZ2AIDRxA4AMJrYAQBGEzsAwGhiBwAY7YixU1Uvraprq+rv7oqBAADWaZWVnZcledwOzwEAsCOOGDvd/adJPnUXzAIAsHZ71rWjqrowyYXr2h8AwDpUdx95o6rzk7y1ux+y0k6rjrxTAIA16u461OPuxgIARhM7AMBoq9x6/uokf5nkwVW1v6p+YufHAgBYj5Wu2TnqnbpmBwC4i7lmBwA4IYkdAGA0sQMAjCZ2AIDRxA4AMJrYAQBGEzsAwGhiBwAYTewAAKOJHQBgNLEDAIwmdgCA0cQOADCa2AEARhM7AMBoYgcAGE3sAACjiR0AYDSxAwCMJnYAgNHEDgAwmtgBAEYTOwDAaGIHABhN7AAAo4kdAGA0sQMAjCZ2AIDRxA4AMJrYAQBGEzsAwGhiBwAYbc9O7PSss87KIx7xiJ3Y9WinnXbapkfYdbp70yPsSjfffPOmR9iVzjjjjE2PsOu87nWv2/QIYGUHAJhN7AAAo4kdAGA0sQMAjCZ2AIDRxA4AMJrYAQBGEzsAwGhiBwAYTewAAKOJHQBgNLEDAIwmdgCA0cQOADCa2AEARhM7AMBoYgcAGE3sAACjiR0AYDSxAwCMJnYAgNHEDgAwmtgBAEYTOwDAaGIHABhN7AAAo4kdAGA0sQMAjCZ2AIDRxA4AMJrYAQBGEzsAwGhiBwAYTewAAKOJHQBgtCPGTlU9oKr+pKquqKrLq+oZd8VgAADrsGeFbW5N8qzufn9VnZnk0qq6uLs/uMOzAQAcsyOu7HT3Nd39/uWvP5vkiiT33+nBAADWYZWVnS+pqvOTXJDkvYd47sIkFybJqaeeuo7ZAACO2coXKFfVGUnekOSZ3X3jwc9390Xdvbe7955yyinrnBEAYNtWip2qOjmL0HlVd79xZ0cCAFifVe7GqiQvSXJFd79w50cCAFifVVZ2HpXkqUkeU1WXLT++e4fnAgBYiyNeoNzd70lSd8EsAABr5ycoAwCjiR0AYDSxAwCMJnYAgNHEDgAwmtgBAEYTOwDAaGIHABhN7AAAo4kdAGA0sQMAjCZ2AIDRxA4AMJrYAQBGEzsAwGhiBwAYTewAAKOJHQBgNLEDAIwmdgCA0cQOADCa2AEARhM7AMBoYgcAGE3sAACjiR0AYDSxAwCMJnYAgNHEDgAwmtgBAEYTOwDAaGIHABhN7AAAo+3ZiZ3efvvt+cIXvrATux7tnve856ZH2HU+/elPb3qEXemMM87Y9Ai70n3ve99NjwBsg5UdAGA0sQMAjCZ2AIDRxA4AMJrYAQBGEzsAwGhiBwAYTewAAKOJHQBgNLEDAIwmdgCA0cQOADCa2AEARhM7AMBoYgcAGE3sAACjiR0AYDSxAwCMJnYAgNHEDgAwmtgBAEYTOwDAaGIHABhN7AAAo4kdAGA0sQMAjCZ2AIDRxA4AMJrYAQBGEzsAwGhiBwAYTewAAKOJHQBgNLEDAIwmdgCA0Y4YO1V1alW9r6o+UFWXV9UL7orBAADWYc8K23wxyWO6+6aqOjnJe6rqj7r7r3Z4NgCAY3bE2OnuTnLT8tOTlx+9k0MBAKzLStfsVNVJVXVZkmuTXNzd7z3ENhdW1b6q2nfLLbeseUwAgO1ZKXa6+7bufliS85I8vKoecohtLuruvd299+STT17zmAAA23NUd2N192eSvDvJ43ZiGACAdVvlbqxzqurs5a9PS/LtST60w3MBAKzFKndjnZvk5VV1UhZx9NrufuvOjgUAsB6r3I31N0kuuAtmAQBYOz9BGQAYTewAAKOJHQBgNLEDAIwmdgCA0cQOADCa2AEARhM7AMBoYgcAGE3sAACjiR0AYDSxAwCMJnYAgNHEDgAwmtgBAEYTOwDAaGIHABhN7AAAo4kdAGA0sQMAjCZ2AIDRxA4AMJrYAQBGEzsAwGhiBwAYTewAAKOJHQBgNLEDAIwmdgCA0cQOADCa2AEARhM7AMBoYgcAGK26e+073bt3b+/bt2/t+wVgd6mqTY/ACaS7D/kXzsoOADCa2AEARhM7AMBoYgcAGE3sAACjiR0AYDSxAwCMJnYAgNHEDgAwmtgBAEYTOwDAaGIHABhN7AAAo4kdAGA0sQMAjCZ2AIDRxA4AMJrYAQBGEzsAwGhiBwAYTewAAKOJHQBgNLEDAIwmdgCA0cQOADCa2AEARhM7AMBoYgcAGE3sAACjiR0AYDSxAwCMJnYAgNHEDgAwmtgBAEYTOwDAaCvHTlWdVFV/XVVv3cmBAADW6WhWdp6R5IqdGgQAYCesFDtVdV6SJyR58c6OAwCwXquu7LwoybOT3H5nG1TVhVW1r6r2XXfddeuYDQDgmB0xdqrqiUmu7e5LD7ddd1/U3Xu7e+8555yztgEBAI7FKis7j0rypKr6WJLXJHlMVb1yR6cCAFiTI8ZOdz+3u8/r7vOTPCXJH3f3j+z4ZAAAa+Dn7AAAo+05mo27+91J3r0jkwAA7AArOwDAaGIHABhN7AAAo4kdAGA0sQMAjCZ2AIDRxA4AMJrYAQBGEzsAwGhiBwAYTewAAKOJHQBgNLEDAIwmdgCA0cQOADCa2AEARhM7AMBoYgcAGE3sAACjiR0AYDSxAwCMJnYAgNHEDgAwmtgBAEYTOwDAaGIHABhN7AAAo4kdAGA0sQMAjCZ2AIDRxA4AMJrYAQBG27MTO/3EJz6R5z3veTuxa7iD2267bdMj7Eq33nrrpkfYlS644IJNjwBsg5UdAGA0sQMAjCZ2AIDRxA4AMJrYAQBGEzsAwGhiBwAYTewAAKOJHQBgNLEDAIwmdgCA0cQOADCa2AEARhM7AMBoYgcAGE3sAACjiR0AYDSxAwCMJnYAgNHEDgAwmtgBAEYTOwDAaGIHABhN7AAAo4kdAGA0sQMAjCZ2AIDRxA4AMJrYAQBGEzsAwGhiBwAYTewAAKOJHQBgNLEDAIwmdgCA0fasslFVfSzJZ5PcluTW7t67k0MBAKzLSrGz9G3dff2OTQIAsAOcxgIARls1djrJu6rq0qq68FAbVNWFVbWvqvZ9/vOfX9+EAADHYNXTWI/q7qur6quSXFxVH+ruP926QXdflOSiJDn33HN7zXMCAGzLSis73X318p/XJnlTkofv5FAAAOtyxNipqtOr6swDv07ynUn+bqcHAwBYh1VOY90nyZuq6sD2v9fd79jRqQAA1uSIsdPdVyZ56F0wCwDA2rn1HAAYTewAAKOJHQBgNLEDAIwmdgCA0cQOADCa2AEARhM7AMBoYgcAGE3sAACjiR0AYDSxAwCMJnYAgNHEDgAwmtgBAEYTOwDAaGIHABhN7AAAo4kdAGA0sQMAjCZ2AIDRxA4AMJrYAQBGEzsAwGhiBwAYTewAAKOJHQBgNLEDAIwmdgCA0cQOADCa2AEARhM7AMBoYgcAGK26e+07Pemkk/qMM85Y+36nO/300zc9wq7zxS9+cdMj7Eo333zzpkfYle52N98fHq0bb7xx0yNwAunuOtTj/s0FAEYTOwDAaGIHABhN7AAAo4kdAGA0sQMAjCZ2AIDRxA4AMJrYAQBGEzsAwGhiBwAYTewAAKOJHQBgNLEDAIwmdgCA0cQOADCa2AEARhM7AMBoYgcAGE3sAACjiR0AYDSxAwCMJnYAgNHEDgAwmtgBAEYTOwDAaGIHABhN7AAAo4kdAGA0sQMAjCZ2AIDRxA4AMJrYAQBGEzsAwGhiBwAYbaXYqaqzq+r1VfWhqrqiqh6x04MBAKzDnhW3+7Uk7+ju76+qU5LcfQdnAgBYmyPGTlWdleTRSX48Sbr75iQ37+xYAADrscpprK9Jcl2S36mqv66qF1fV6QdvVFUXVtW+qtrX3WsfFABgO1aJnT1JvjHJb3X3BUk+l+Q5B2/U3Rd1997u3ltVax4TAGB7Vomd/Un2d/d7l5+/Pov4AQA47h0xdrr7k0muqqoHLx96bJIP7uhUAABrsurdWE9P8qrlnVhXJnnazo0EALA+K8VOd1+WZO/OjgIAsH5+gjIAMJrYAQBGEzsAwGhiBwAYTewAAKOJHQBgNLEDAIwmdgCA0cQOADCa2AEARhM7AMBoYgcAGE3sAACjiR0AYDSxAwCMJnYAgNHEDgAwmtgBAEYTOwDAaGIHABhN7AAAo4kdAGA0sQMAjCZ2AIDRxA4AMJrYAQBGEzsAwGhiBwAYTewAAKOJHQBgNLEDAIwmdgCA0cQOADBadff6d1p1XZKPr33Hx+7eSa7f9BC7kOO2PY7b0XPMtsdx2x7H7egdz8fsQd19zqGe2JHYOV5V1b7u3rvpOXYbx217HLej55htj+O2PY7b0dutx8xpLABgNLEDAIx2osXORZseYJdy3LbHcTt6jtn2OG7b47gdvV15zE6oa3YAgBPPibayAwCcYMQOADDaCRM7VfW4qvr7qvpIVT1n0/PsBlX10qq6tqr+btOz7BZV9YCq+pOquqKqLq+qZ2x6pt2gqk6tqvdV1QeWx+0Fm55pt6iqk6rqr6vqrZueZbeoqo9V1d9W1WVVtW/T8+wWVXV2Vb2+qj60/G/cIzY906pOiGt2quqkJB9O8h1J9ie5JMkPdvcHNzrYca6qHp3kpiS/290P2fQ8u0FVnZvk3O5+f1WdmeTSJN/n79rhVVUlOb27b6qqk5O8J8kzuvuvNjzaca+qfibJ3iRndfcTNz3PblBVH0uyt7uP1x+Od1yqqpcn+bPufnFVnZLk7t39mQ2PtZITZWXn4Uk+0t1XdvfNSV6T5Hs3PNNxr7v/NMmnNj3HbtLd13T3+5e//mySK5Lcf7NTHf964ablpycvP+Z/J3aMquq8JE9I8uJNz8JsVXVWkkcneUmSdPfNuyV0khMndu6f5Kotn++PL0DssKo6P8kFSd674VF2heXpmMuSXJvk4u523I7sRUmeneT2Dc+x23SSd1XVpVV14aaH2SW+Jsl1SX5nedr0xVV1+qaHWtWJEjt1iMd818iOqaozkrwhyTO7+8ZNz7MbdPdt3f2wJOcleXhVOXV6GFX1xCTXdvelm55lF3pUd39jkscn+anlKXsOb0+Sb0zyW919QZLPJdk117+eKLGzP8kDtnx+XpKrNzQLwy2vOXlDkld19xs3Pc9us1waf3eSx212kuPeo5I8aXn9yWuSPKaqXrnZkXaH7r56+c9rk7wpi0sdOLz9SfZvWXF9fRbxsyucKLFzSZKvraqvXl5U9ZQkb97wTAy0vND2JUmu6O4Xbnqe3aKqzqmqs5e/Pi3Jtyf50EaHOs5193O7+7zuPj+L/6b9cXf/yIbHOu5V1enLmweyPA3znUnccXoE3f3JJFdV1YOXDz02ya658WLPpge4K3T3rVX100nemeSkJC/t7ss3PNZxr6peneRbk9y7qvYneX53v2SzUx33HpXkqUn+dnn9SZL8XHe/fXMj7QrnJnn58s7JuyV5bXe7lZqdcJ8kb1p8X5I9SX6vu9+x2ZF2jacnedVy0eDKJE/b8DwrOyFuPQcATlwnymksAOAEJXYAgNHEDgAwmtgBAEYTOwDAaGIHABhN7AAAo/0/dg2Er+YDG+cAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import tensorflow_docs as tfdocs\n",
    "# import tensorflow_docs.modeling\n",
    "# import tensorflow_docs.plots\n",
    "\n",
    "# plotter = tfdocs.plots.HistoryPlotter(metric = 'binary_crossentropy', smoothing_std=10)\n",
    "# plotter.plot(history)\n",
    "import sklearn.metrics\n",
    "\n",
    "Y_test_hat=model2.predict(test_generator)\n",
    "y_test_hat=Y_test_hat.argmax(axis=-1)\n",
    "y_test = [int(i) for i in y_test]\n",
    "\n",
    "\n",
    "con_matrix = sklearn.metrics.confusion_matrix(y_test,y_test_hat)\n",
    "acc=np.diag(con_matrix).sum().astype(float)/con_matrix.sum()\n",
    "\n",
    "print('The accuracy of the network model3 is: ', acc)\n",
    "\n",
    "min = np.min(con_matrix)\n",
    "max = np.max(con_matrix)\n",
    "temp_mat = con_matrix - min\n",
    "temp_mat = con_matrix/max\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(normalize_Xtrain(con_matrix)[0], cmap='gray')\n",
    "plt.title('Confusion Matrix for Model2')\n",
    "\n",
    "\n",
    "\n",
    "print(history.history.keys())\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(np.arange(0, len(history.history['categorical_accuracy'])), history.history['categorical_accuracy'])\n",
    "plt.plot(np.arange(0, len(history.history['val_categorical_accuracy'])), history.history['val_categorical_accuracy'])\n",
    "plt.legend(('Training Accuracy', 'Validation Accuracy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-506eb8d79dda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m model2.fit(train_generator, steps_per_epoch=step_size_train, epochs=10, verbose=1,\\\n\u001b[1;32m      2\u001b[0m                      \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep_size_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                      validation_freq=1, class_weight=class_weights, max_queue_size=100, workers=20, use_multiprocessing=True)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1062\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1064\u001b[0;31m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1110\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, shuffle, workers, use_multiprocessing, max_queue_size, model, **kwargs)\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m         **kwargs)\n\u001b[0m\u001b[1;32m    910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, workers, use_multiprocessing, max_queue_size, model, **kwargs)\u001b[0m\n\u001b[1;32m    777\u001b[0m     \u001b[0;31m# Since we have to know the dtype of the python generator when we build the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m     \u001b[0;31m# dataset, we have to look at a batch to infer the structure.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m     \u001b[0mpeek\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_peek_and_restore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m     \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m     \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_tensorlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_peek_and_restore\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    911\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_peek_and_restore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 913\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m   def _handle_multiprocessing(self, x, workers, use_multiprocessing,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     64\u001b[0m         index_array = self.index_array[self.batch_size * idx:\n\u001b[1;32m     65\u001b[0m                                        self.batch_size * (idx + 1)]\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36m_get_batches_of_transformed_samples\u001b[0;34m(self, index_array)\u001b[0m\n\u001b[1;32m    229\u001b[0m                            \u001b[0mcolor_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolor_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m                            \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m                            interpolation=self.interpolation)\n\u001b[0m\u001b[1;32m    232\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0;31m# Pillow images should be closed after `load_img`,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mfits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'silentfix'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'grayscale'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/astropy/io/fits/hdu/hdulist.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0moutput_verify\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'output_verify'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'exception'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_verify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_verify\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/astropy/io/fits/hdu/hdulist.py\u001b[0m in \u001b[0;36mclose\u001b[0;34m(self, output_verify, verbose, closed)\u001b[0m\n\u001b[1;32m    975\u001b[0m             \u001b[0;31m# Give individual HDUs an opportunity to do on-close cleanup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mhdu\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m                 \u001b[0mhdu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclosed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/astropy/io/fits/hdu/compressed.py\u001b[0m in \u001b[0;36m_close\u001b[0;34m(self, closed)\u001b[0m\n\u001b[1;32m   1856\u001b[0m         if (closed and self._data_loaded and\n\u001b[1;32m   1857\u001b[0m                 _get_array_mmap(self.compressed_data) is not None):\n\u001b[0;32m-> 1858\u001b[0;31m             \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompressed_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m     \u001b[0;31m# TODO: This was copied right out of _ImageBaseHDU; get rid of it once we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/astropy/utils/decorators.py\u001b[0m in \u001b[0;36m__delete__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    777\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__delete__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfdel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfdel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_key\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/astropy/io/fits/hdu/compressed.py\u001b[0m in \u001b[0;36mcompressed_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1446\u001b[0m             \u001b[0;31m# since this reference leak can sometimes hang around longer than\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m             \u001b[0;31m# welcome go ahead and force a garbage collection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1448\u001b[0;31m             \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# model2.fit(train_generator, steps_per_epoch=step_size_train, epochs=10, verbose=1,\\\n",
    "#                      callbacks=callbacks_list, validation_data=val_generator, validation_steps=step_size_val,\\\n",
    "#                      validation_freq=1, class_weight=class_weights, max_queue_size=100, workers=20, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ImageDataGenerator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "\u001b[1;32m<ipython-input-364-53cae2e69166>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m----> 1\u001b[1;33m model2.fit(ImageDataGenerator, steps_per_epoch=step_size_train, epochs=10, verbose=1,\\\n",
      "\u001b[0m\u001b[0;32m      2\u001b[0m                      \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep_size_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m      3\u001b[0m                      \u001b[0mvalidation_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m      4\u001b[0m                      max_queue_size=100, workers=16, use_multiprocessing=True)\n",
      "\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ImageDataGenerator' is not defined"
     ]
    }
   ],
   "source": [
    "model2.fit(ImageDataGenerator, steps_per_epoch=step_size_train, epochs=10, verbose=1,\\\n",
    "                     callbacks=callbacks_list, validation_data=val_generator, validation_steps=step_size_val,\\\n",
    "                     validation_freq=1, class_weight=class_weights,\\\n",
    "                     max_queue_size=100, workers=16, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method fit in module tensorflow.python.keras.engine.training:\n",
      "\n",
      "fit(x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, validation_batch_size=None, validation_freq=1, max_queue_size=10, workers=1, use_multiprocessing=False) method of tensorflow.python.keras.engine.functional.Functional instance\n",
      "    Trains the model for a fixed number of epochs (iterations on a dataset).\n",
      "    \n",
      "    Arguments:\n",
      "        x: Input data. It could be:\n",
      "          - A Numpy array (or array-like), or a list of arrays\n",
      "            (in case the model has multiple inputs).\n",
      "          - A TensorFlow tensor, or a list of tensors\n",
      "            (in case the model has multiple inputs).\n",
      "          - A dict mapping input names to the corresponding array/tensors,\n",
      "            if the model has named inputs.\n",
      "          - A `tf.data` dataset. Should return a tuple\n",
      "            of either `(inputs, targets)` or\n",
      "            `(inputs, targets, sample_weights)`.\n",
      "          - A generator or `keras.utils.Sequence` returning `(inputs, targets)`\n",
      "            or `(inputs, targets, sample_weights)`.\n",
      "          A more detailed description of unpacking behavior for iterator types\n",
      "          (Dataset, generator, Sequence) is given below.\n",
      "        y: Target data. Like the input data `x`,\n",
      "          it could be either Numpy array(s) or TensorFlow tensor(s).\n",
      "          It should be consistent with `x` (you cannot have Numpy inputs and\n",
      "          tensor targets, or inversely). If `x` is a dataset, generator,\n",
      "          or `keras.utils.Sequence` instance, `y` should\n",
      "          not be specified (since targets will be obtained from `x`).\n",
      "        batch_size: Integer or `None`.\n",
      "            Number of samples per gradient update.\n",
      "            If unspecified, `batch_size` will default to 32.\n",
      "            Do not specify the `batch_size` if your data is in the\n",
      "            form of datasets, generators, or `keras.utils.Sequence` instances\n",
      "            (since they generate batches).\n",
      "        epochs: Integer. Number of epochs to train the model.\n",
      "            An epoch is an iteration over the entire `x` and `y`\n",
      "            data provided.\n",
      "            Note that in conjunction with `initial_epoch`,\n",
      "            `epochs` is to be understood as \"final epoch\".\n",
      "            The model is not trained for a number of iterations\n",
      "            given by `epochs`, but merely until the epoch\n",
      "            of index `epochs` is reached.\n",
      "        verbose: 0, 1, or 2. Verbosity mode.\n",
      "            0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
      "            Note that the progress bar is not particularly useful when\n",
      "            logged to a file, so verbose=2 is recommended when not running\n",
      "            interactively (eg, in a production environment).\n",
      "        callbacks: List of `keras.callbacks.Callback` instances.\n",
      "            List of callbacks to apply during training.\n",
      "            See `tf.keras.callbacks`. Note `tf.keras.callbacks.ProgbarLogger`\n",
      "            and `tf.keras.callbacks.History` callbacks are created automatically\n",
      "            and need not be passed into `model.fit`.\n",
      "            `tf.keras.callbacks.ProgbarLogger` is created or not based on\n",
      "            `verbose` argument to `model.fit`.\n",
      "        validation_split: Float between 0 and 1.\n",
      "            Fraction of the training data to be used as validation data.\n",
      "            The model will set apart this fraction of the training data,\n",
      "            will not train on it, and will evaluate\n",
      "            the loss and any model metrics\n",
      "            on this data at the end of each epoch.\n",
      "            The validation data is selected from the last samples\n",
      "            in the `x` and `y` data provided, before shuffling. This argument is\n",
      "            not supported when `x` is a dataset, generator or\n",
      "           `keras.utils.Sequence` instance.\n",
      "        validation_data: Data on which to evaluate\n",
      "            the loss and any model metrics at the end of each epoch.\n",
      "            The model will not be trained on this data. Thus, note the fact\n",
      "            that the validation loss of data provided using `validation_split`\n",
      "            or `validation_data` is not affected by regularization layers like\n",
      "            noise and dropout.\n",
      "            `validation_data` will override `validation_split`.\n",
      "            `validation_data` could be:\n",
      "              - tuple `(x_val, y_val)` of Numpy arrays or tensors\n",
      "              - tuple `(x_val, y_val, val_sample_weights)` of Numpy arrays\n",
      "              - dataset\n",
      "            For the first two cases, `batch_size` must be provided.\n",
      "            For the last case, `validation_steps` could be provided.\n",
      "            Note that `validation_data` does not support all the data types that\n",
      "            are supported in `x`, eg, dict, generator or `keras.utils.Sequence`.\n",
      "        shuffle: Boolean (whether to shuffle the training data\n",
      "            before each epoch) or str (for 'batch'). This argument is ignored\n",
      "            when `x` is a generator. 'batch' is a special option for dealing\n",
      "            with the limitations of HDF5 data; it shuffles in batch-sized\n",
      "            chunks. Has no effect when `steps_per_epoch` is not `None`.\n",
      "        class_weight: Optional dictionary mapping class indices (integers)\n",
      "            to a weight (float) value, used for weighting the loss function\n",
      "            (during training only).\n",
      "            This can be useful to tell the model to\n",
      "            \"pay more attention\" to samples from\n",
      "            an under-represented class.\n",
      "        sample_weight: Optional Numpy array of weights for\n",
      "            the training samples, used for weighting the loss function\n",
      "            (during training only). You can either pass a flat (1D)\n",
      "            Numpy array with the same length as the input samples\n",
      "            (1:1 mapping between weights and samples),\n",
      "            or in the case of temporal data,\n",
      "            you can pass a 2D array with shape\n",
      "            `(samples, sequence_length)`,\n",
      "            to apply a different weight to every timestep of every sample. This\n",
      "            argument is not supported when `x` is a dataset, generator, or\n",
      "           `keras.utils.Sequence` instance, instead provide the sample_weights\n",
      "            as the third element of `x`.\n",
      "        initial_epoch: Integer.\n",
      "            Epoch at which to start training\n",
      "            (useful for resuming a previous training run).\n",
      "        steps_per_epoch: Integer or `None`.\n",
      "            Total number of steps (batches of samples)\n",
      "            before declaring one epoch finished and starting the\n",
      "            next epoch. When training with input tensors such as\n",
      "            TensorFlow data tensors, the default `None` is equal to\n",
      "            the number of samples in your dataset divided by\n",
      "            the batch size, or 1 if that cannot be determined. If x is a\n",
      "            `tf.data` dataset, and 'steps_per_epoch'\n",
      "            is None, the epoch will run until the input dataset is exhausted.\n",
      "            When passing an infinitely repeating dataset, you must specify the\n",
      "            `steps_per_epoch` argument. This argument is not supported with\n",
      "            array inputs.\n",
      "        validation_steps: Only relevant if `validation_data` is provided and\n",
      "            is a `tf.data` dataset. Total number of steps (batches of\n",
      "            samples) to draw before stopping when performing validation\n",
      "            at the end of every epoch. If 'validation_steps' is None, validation\n",
      "            will run until the `validation_data` dataset is exhausted. In the\n",
      "            case of an infinitely repeated dataset, it will run into an\n",
      "            infinite loop. If 'validation_steps' is specified and only part of\n",
      "            the dataset will be consumed, the evaluation will start from the\n",
      "            beginning of the dataset at each epoch. This ensures that the same\n",
      "            validation samples are used every time.\n",
      "        validation_batch_size: Integer or `None`.\n",
      "            Number of samples per validation batch.\n",
      "            If unspecified, will default to `batch_size`.\n",
      "            Do not specify the `validation_batch_size` if your data is in the\n",
      "            form of datasets, generators, or `keras.utils.Sequence` instances\n",
      "            (since they generate batches).\n",
      "        validation_freq: Only relevant if validation data is provided. Integer\n",
      "            or `collections_abc.Container` instance (e.g. list, tuple, etc.).\n",
      "            If an integer, specifies how many training epochs to run before a\n",
      "            new validation run is performed, e.g. `validation_freq=2` runs\n",
      "            validation every 2 epochs. If a Container, specifies the epochs on\n",
      "            which to run validation, e.g. `validation_freq=[1, 2, 10]` runs\n",
      "            validation at the end of the 1st, 2nd, and 10th epochs.\n",
      "        max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
      "            input only. Maximum size for the generator queue.\n",
      "            If unspecified, `max_queue_size` will default to 10.\n",
      "        workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
      "            only. Maximum number of processes to spin up\n",
      "            when using process-based threading. If unspecified, `workers`\n",
      "            will default to 1. If 0, will execute the generator on the main\n",
      "            thread.\n",
      "        use_multiprocessing: Boolean. Used for generator or\n",
      "            `keras.utils.Sequence` input only. If `True`, use process-based\n",
      "            threading. If unspecified, `use_multiprocessing` will default to\n",
      "            `False`. Note that because this implementation relies on\n",
      "            multiprocessing, you should not pass non-picklable arguments to\n",
      "            the generator as they can't be passed easily to children processes.\n",
      "    \n",
      "    Unpacking behavior for iterator-like inputs:\n",
      "        A common pattern is to pass a tf.data.Dataset, generator, or\n",
      "      tf.keras.utils.Sequence to the `x` argument of fit, which will in fact\n",
      "      yield not only features (x) but optionally targets (y) and sample weights.\n",
      "      Keras requires that the output of such iterator-likes be unambiguous. The\n",
      "      iterator should return a tuple of length 1, 2, or 3, where the optional\n",
      "      second and third elements will be used for y and sample_weight\n",
      "      respectively. Any other type provided will be wrapped in a length one\n",
      "      tuple, effectively treating everything as 'x'. When yielding dicts, they\n",
      "      should still adhere to the top-level tuple structure.\n",
      "      e.g. `({\"x0\": x0, \"x1\": x1}, y)`. Keras will not attempt to separate\n",
      "      features, targets, and weights from the keys of a single dict.\n",
      "        A notable unsupported data type is the namedtuple. The reason is that\n",
      "      it behaves like both an ordered datatype (tuple) and a mapping\n",
      "      datatype (dict). So given a namedtuple of the form:\n",
      "          `namedtuple(\"example_tuple\", [\"y\", \"x\"])`\n",
      "      it is ambiguous whether to reverse the order of the elements when\n",
      "      interpreting the value. Even worse is a tuple of the form:\n",
      "          `namedtuple(\"other_tuple\", [\"x\", \"y\", \"z\"])`\n",
      "      where it is unclear if the tuple was intended to be unpacked into x, y,\n",
      "      and sample_weight or passed through as a single element to `x`. As a\n",
      "      result the data processing code will simply raise a ValueError if it\n",
      "      encounters a namedtuple. (Along with instructions to remedy the issue.)\n",
      "    \n",
      "    Returns:\n",
      "        A `History` object. Its `History.history` attribute is\n",
      "        a record of training loss values and metrics values\n",
      "        at successive epochs, as well as validation loss values\n",
      "        and validation metrics values (if applicable).\n",
      "    \n",
      "    Raises:\n",
      "        RuntimeError: 1. If the model was never compiled or,\n",
      "        2. If `model.fit` is  wrapped in `tf.function`.\n",
      "    \n",
      "        ValueError: In case of mismatch between the provided input data\n",
      "            and what the model expects or when the input data is empty.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(model2.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model2 = load_model('model.best.hdf5', custom_objects={'categorical_tnr': categorical_tnr,\\\n",
    "                                                       'categorical_tpr': categorical_tpr,\\\n",
    "                                                       'categorical_tss': categorical_tss})\n",
    "model2.compile(loss='categorical_crossentropy', optimizer=adam_opt,\\\n",
    "               metrics=['categorical_accuracy',categorical_tnr,categorical_tpr,categorical_tss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 93645 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "test_generator = test_datagen.flow_from_directory('VGG_AR_Dataset/TestSet_224',\\\n",
    "                                                target_size=(224,224), color_mode='rgb',\\\n",
    "                                                batch_size=128, class_mode='categorical',\\\n",
    "                                                shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "732/732 [==============================] - 161s 220ms/step - loss: 0.5478 - categorical_accuracy: 0.7607 - categorical_tnr: 0.7761 - categorical_tpr: 0.6990 - categorical_tss: 0.4751\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5457175374031067,\n",
       " 0.7646430730819702,\n",
       " 0.7795358300209045,\n",
       " 0.7046583890914917,\n",
       " 0.48419439792633057]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(model2.evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(test_generator.labels==0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(test_generator.labels==1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
