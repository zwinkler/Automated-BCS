{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zacha\\anaconda3\\envs\\ML_env\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from PIL import Image as pil_image\n",
    "import imageio\n",
    "import tensorflow\n",
    "import sklearn.metrics\n",
    "import itertools\n",
    "from tensorflow.keras.layers import Input\n",
    "import tensorflow.keras.applications\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv2D, ReLU, concatenate, MaxPool2D, AvgPool2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32309dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_classes = 100\n",
    "# input_shape = (32, 32, 3)\n",
    "\n",
    "# (x_train, y_train), (x_test, y_test) = keras.datasets.cifar100.load_data()\n",
    "\n",
    "# print(f\"x_train shape: {x_train.shape} - y_train shape: {y_train.shape}\")\n",
    "# print(f\"x_test shape: {x_test.shape} - y_test shape: {y_test.shape}\")\n",
    "# print(y_train[0:2])\n",
    "# print(x_train[0, :, :, 0])\n",
    "# #list_dframe = list(train_df[\"class\"][0:10].astype(int))\n",
    "\n",
    "# # v = np.reshape(list_dframe, (-1, 1))\n",
    "# # print(v)\n",
    "\n",
    "# print(np.mean(x_train))\n",
    "# print(np.var(x_train))\n",
    "# print(np.std(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c292caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.transform\n",
    "\n",
    "train_df = pd.read_csv('train_data.csv',dtype=str)\n",
    "val_df = pd.read_csv('val_data.csv',dtype=str)\n",
    "test_df = pd.read_csv('test_data.csv',dtype=str)\n",
    "\n",
    "# num_imgs_train = len(train_df['class'])\n",
    "# x_train = np.zeros((num_imgs_train, 224, 224, 3))\n",
    "\n",
    "# random_names = np.random.random_integers(num_imgs_train, size=(num_imgs_train,))\n",
    "# img_names = list(train_df['filename'][random_names])\n",
    "# y_train = np.expand_dims(np.asarray(train_df['class'][random_names]).astype(int), axis=1)-2\n",
    "\n",
    "# print(np.min(y_train))\n",
    "\n",
    "# for i in range(0,num_imgs_train):\n",
    "#     img = imageio.imread(img_names[i])\n",
    "#     x_train[i, :, :, :] = skimage.transform.resize(img, (224, 224, 3))\n",
    "\n",
    "def read_data(data_frame):\n",
    "    num_imgs_train = len(train_df['class'])\n",
    "    x_train = np.zeros((num_imgs_train, 224, 224, 3))\n",
    "\n",
    "    img_names = list(train_df['filename'])\n",
    "    y_train = np.expand_dims(np.asarray(train_df['class']).astype(int), axis=1)-2\n",
    "\n",
    "\n",
    "    for i in range(0,num_imgs_train):\n",
    "        img = imageio.imread(img_names[i])\n",
    "        x_train[i, :, :, :] = skimage.transform.resize(img, (224, 224, 3))\n",
    "    return x_train, y_train\n",
    "\n",
    "x_train, y_train = read_data(train_df)\n",
    "x_val, y_val = read_data(val_df)\n",
    "x_test, y_test = read_data(test_df)\n",
    "\n",
    "# print(np.shape(x_train_2))\n",
    "# print(np.shape(y_train_2))\n",
    "# print(y_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d86a6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "weight_decay = 0.0001\n",
    "batch_size = 256\n",
    "num_epochs = 100\n",
    "image_size = 224 #72  # We'll resize input images to this size\n",
    "patch_size = 32 #6  # Size of the patches to be extract from the input images\n",
    "num_patches = (image_size // patch_size) ** 2\n",
    "projection_dim = 64\n",
    "num_heads = 4\n",
    "transformer_units = [\n",
    "    projection_dim * 2,\n",
    "    projection_dim,\n",
    "]  # Size of the transformer layers\n",
    "transformer_layers = 8\n",
    "mlp_head_units = [2048, 1024]  # Size of the dense layers of the final classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e43c4cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 476 validated image filenames.\n",
      "Found 2346 validated image filenames.\n",
      "Found 2950 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "num_classes = 5\n",
    "input_shape = (224, 224, 3)\n",
    "\n",
    "train_df = pd.read_csv('train_data.csv',dtype=str)\n",
    "val_df = pd.read_csv('val_data.csv',dtype=str)\n",
    "test_df = pd.read_csv('test_data.csv',dtype=str)\n",
    "\n",
    "# train_df[\"class\"] = train_df[\"class\"].astype(str).astype(int)\n",
    "# val_df[\"class\"] = val_df[\"class\"].astype(str).astype(int)\n",
    "# test_df[\"class\"] = test_df[\"class\"].astype(str).astype(int)\n",
    "\n",
    "# train_df[\"class\"] = np.expand_dims(np.asarray(train_df[\"class\"]).astype(int), axis=1)\n",
    "# val_df[\"class\"] = np.expand_dims(np.asarray(val_df[\"class\"]).astype(int), axis=1)\n",
    "# test_df[\"class\"] = np.expand_dims(np.asarray(test_df[\"class\"]).astype(int), axis=1)\n",
    "\n",
    "\n",
    "#train_df_class = np.reshape(list(train_df[\"class\"].astype(int)), (-1, 1))\n",
    "# val_df_class = np.reshape(val_df[\"class\"], (-1, 1))\n",
    "# test_df_class = np.reshape(test_df[\"class\"], (-1, 1))\n",
    "\n",
    "#print(train_df_class[0:10])\n",
    "#print(np.transpose(np.array(train_df[\"class\"][0:10])))\n",
    "\n",
    "#Something about casting these labels to floats makes my loss nans?\n",
    "\n",
    "train_datagen = ImageDataGenerator(fill_mode = \"reflect\", data_format = \"channels_last\")\n",
    "train_generator = train_datagen.flow_from_dataframe(dataframe=train_df,\\\n",
    "                                                    directory='',\\\n",
    "                                                    xcol='filename',y_col=\"class\",\\\n",
    "                                                    target_size=(image_size,image_size), color_mode='rgb',\\\n",
    "                                                    batch_size=batch_size, class_mode='raw',\\\n",
    "                                                    shuffle=True) #RETURN TO TRUEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
    "val_datagen = ImageDataGenerator(fill_mode = \"reflect\", data_format = \"channels_last\")\n",
    "val_generator = val_datagen.flow_from_dataframe(dataframe=val_df,\\\n",
    "                                                directory = '',\\\n",
    "                                                xcol='filename',ycol=\"class\",\\\n",
    "                                                target_size=(image_size,image_size), color_mode='rgb',\\\n",
    "                                                batch_size=batch_size, class_mode='raw',\\\n",
    "                                                shuffle=True)\n",
    "test_datagen = ImageDataGenerator(fill_mode = \"reflect\", data_format = \"channels_last\")\n",
    "test_generator = test_datagen.flow_from_dataframe(dataframe=test_df,\\\n",
    "                                                directory = '',\\\n",
    "                                                xcol='filename',ycol=\"class\",\\\n",
    "                                                target_size=(image_size,image_size), color_mode='rgb',\\\n",
    "                                                batch_size=batch_size, class_mode='raw',\\\n",
    "                                                shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "174e0b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.Normalization(),\n",
    "        layers.Resizing(image_size, image_size),\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(factor=0.02),\n",
    "        layers.RandomZoom(\n",
    "            height_factor=0.2, width_factor=0.2\n",
    "        ),\n",
    "    ],\n",
    "    name=\"data_augmentation\",\n",
    ")\n",
    "\n",
    "# Compute the mean and the variance of the training data for normalization.\n",
    "#data_augmentation.layers[0].adapt(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50cf8346",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(x, hidden_units, dropout_rate):\n",
    "    for units in hidden_units:\n",
    "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68184625",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Patches(layers.Layer):\n",
    "    def __init__(self, patch_size):\n",
    "        super(Patches, self).__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
    "            strides=[1, self.patch_size, self.patch_size, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        patch_dims = patches.shape[-1]\n",
    "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
    "        return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09c8ed1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: 224 X 224\n",
      "Patch size: 32 X 32\n",
      "Patches per image: 49\n",
      "Elements per patch: 3072\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x288 with 49 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "image = imageio.imread(train_df[\"filename\"][0])\n",
    "plt.imshow(image.astype(\"uint8\"))\n",
    "plt.axis(\"off\")\n",
    "\n",
    "resized_image = tf.image.resize(\n",
    "    tf.convert_to_tensor([image]), size=(image_size, image_size)\n",
    ")\n",
    "patches = Patches(patch_size)(resized_image)\n",
    "print(f\"Image size: {image_size} X {image_size}\")\n",
    "print(f\"Patch size: {patch_size} X {patch_size}\")\n",
    "print(f\"Patches per image: {patches.shape[1]}\")\n",
    "print(f\"Elements per patch: {patches.shape[-1]}\")\n",
    "\n",
    "n = int(np.sqrt(patches.shape[1]))\n",
    "plt.figure(figsize=(4, 4))\n",
    "for i, patch in enumerate(patches[0]):\n",
    "    ax = plt.subplot(n, n, i + 1)\n",
    "    patch_img = tf.reshape(patch, (patch_size, patch_size, 3))\n",
    "    plt.imshow(patch_img.numpy().astype(\"uint8\"))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca72a3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEncoder(layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim):\n",
    "        super(PatchEncoder, self).__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection = layers.Dense(units=projection_dim)\n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=projection_dim\n",
    "        )\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
    "        return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5d9e8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vit_classifier():\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    # Augment data.\n",
    "    augmented = data_augmentation(inputs)\n",
    "    # Create patches.\n",
    "    patches = Patches(patch_size)(augmented)\n",
    "    # Encode patches.\n",
    "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
    "\n",
    "    # Create multiple layers of the Transformer block.\n",
    "    for _ in range(transformer_layers):\n",
    "        # Layer normalization 1.\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "        # Create a multi-head attention layer.\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
    "        )(x1, x1)\n",
    "        # Skip connection 1.\n",
    "        x2 = layers.Add()([attention_output, encoded_patches])\n",
    "        # Layer normalization 2.\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        # MLP.\n",
    "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
    "        # Skip connection 2.\n",
    "        encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "    # Create a [batch_size, projection_dim] tensor.\n",
    "    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "    representation = layers.Flatten()(representation)\n",
    "    representation = layers.Dropout(0.5)(representation)\n",
    "    # Add MLP.\n",
    "    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n",
    "    # Classify outputs.\n",
    "    logits = layers.Dense(num_classes)(features)\n",
    "    # Create the Keras model.\n",
    "    model = keras.Model(inputs=inputs, outputs=logits)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82735c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " data_augmentation (Sequential)  (None, 224, 224, 3)  7          ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " patches_1 (Patches)            (None, None, 3072)   0           ['data_augmentation[0][0]']      \n",
      "                                                                                                  \n",
      " patch_encoder (PatchEncoder)   (None, 49, 64)       199808      ['patches_1[0][0]']              \n",
      "                                                                                                  \n",
      " layer_normalization (LayerNorm  (None, 49, 64)      128         ['patch_encoder[0][0]']          \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " multi_head_attention (MultiHea  (None, 49, 64)      66368       ['layer_normalization[0][0]',    \n",
      " dAttention)                                                      'layer_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 49, 64)       0           ['multi_head_attention[0][0]',   \n",
      "                                                                  'patch_encoder[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_1 (LayerNo  (None, 49, 64)      128         ['add[0][0]']                    \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 49, 128)      8320        ['layer_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 49, 128)      0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 49, 64)       8256        ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 49, 64)       0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 49, 64)       0           ['dropout_1[0][0]',              \n",
      "                                                                  'add[0][0]']                    \n",
      "                                                                                                  \n",
      " layer_normalization_2 (LayerNo  (None, 49, 64)      128         ['add_1[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (MultiH  (None, 49, 64)      66368       ['layer_normalization_2[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 49, 64)       0           ['multi_head_attention_1[0][0]', \n",
      "                                                                  'add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_3 (LayerNo  (None, 49, 64)      128         ['add_2[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 49, 128)      8320        ['layer_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 49, 128)      0           ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 49, 64)       8256        ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 49, 64)       0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 49, 64)       0           ['dropout_3[0][0]',              \n",
      "                                                                  'add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_4 (LayerNo  (None, 49, 64)      128         ['add_3[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_2 (MultiH  (None, 49, 64)      66368       ['layer_normalization_4[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 49, 64)       0           ['multi_head_attention_2[0][0]', \n",
      "                                                                  'add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_5 (LayerNo  (None, 49, 64)      128         ['add_4[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 49, 128)      8320        ['layer_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 49, 128)      0           ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 49, 64)       8256        ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 49, 64)       0           ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 49, 64)       0           ['dropout_5[0][0]',              \n",
      "                                                                  'add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_6 (LayerNo  (None, 49, 64)      128         ['add_5[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_3 (MultiH  (None, 49, 64)      66368       ['layer_normalization_6[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 49, 64)       0           ['multi_head_attention_3[0][0]', \n",
      "                                                                  'add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_7 (LayerNo  (None, 49, 64)      128         ['add_6[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 49, 128)      8320        ['layer_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 49, 128)      0           ['dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 49, 64)       8256        ['dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 49, 64)       0           ['dense_8[0][0]']                \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 49, 64)       0           ['dropout_7[0][0]',              \n",
      "                                                                  'add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_8 (LayerNo  (None, 49, 64)      128         ['add_7[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " multi_head_attention_4 (MultiH  (None, 49, 64)      66368       ['layer_normalization_8[0][0]',  \n",
      " eadAttention)                                                    'layer_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 49, 64)       0           ['multi_head_attention_4[0][0]', \n",
      "                                                                  'add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_9 (LayerNo  (None, 49, 64)      128         ['add_8[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 49, 128)      8320        ['layer_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 49, 128)      0           ['dense_9[0][0]']                \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 49, 64)       8256        ['dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 49, 64)       0           ['dense_10[0][0]']               \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 49, 64)       0           ['dropout_9[0][0]',              \n",
      "                                                                  'add_8[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_10 (LayerN  (None, 49, 64)      128         ['add_9[0][0]']                  \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_5 (MultiH  (None, 49, 64)      66368       ['layer_normalization_10[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " add_10 (Add)                   (None, 49, 64)       0           ['multi_head_attention_5[0][0]', \n",
      "                                                                  'add_9[0][0]']                  \n",
      "                                                                                                  \n",
      " layer_normalization_11 (LayerN  (None, 49, 64)      128         ['add_10[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 49, 128)      8320        ['layer_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)           (None, 49, 128)      0           ['dense_11[0][0]']               \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 49, 64)       8256        ['dropout_10[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)           (None, 49, 64)       0           ['dense_12[0][0]']               \n",
      "                                                                                                  \n",
      " add_11 (Add)                   (None, 49, 64)       0           ['dropout_11[0][0]',             \n",
      "                                                                  'add_10[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_12 (LayerN  (None, 49, 64)      128         ['add_11[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_6 (MultiH  (None, 49, 64)      66368       ['layer_normalization_12[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " add_12 (Add)                   (None, 49, 64)       0           ['multi_head_attention_6[0][0]', \n",
      "                                                                  'add_11[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_13 (LayerN  (None, 49, 64)      128         ['add_12[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 49, 128)      8320        ['layer_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_12 (Dropout)           (None, 49, 128)      0           ['dense_13[0][0]']               \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 49, 64)       8256        ['dropout_12[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_13 (Dropout)           (None, 49, 64)       0           ['dense_14[0][0]']               \n",
      "                                                                                                  \n",
      " add_13 (Add)                   (None, 49, 64)       0           ['dropout_13[0][0]',             \n",
      "                                                                  'add_12[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_14 (LayerN  (None, 49, 64)      128         ['add_13[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " multi_head_attention_7 (MultiH  (None, 49, 64)      66368       ['layer_normalization_14[0][0]', \n",
      " eadAttention)                                                    'layer_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " add_14 (Add)                   (None, 49, 64)       0           ['multi_head_attention_7[0][0]', \n",
      "                                                                  'add_13[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_15 (LayerN  (None, 49, 64)      128         ['add_14[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (None, 49, 128)      8320        ['layer_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_14 (Dropout)           (None, 49, 128)      0           ['dense_15[0][0]']               \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (None, 49, 64)       8256        ['dropout_14[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_15 (Dropout)           (None, 49, 64)       0           ['dense_16[0][0]']               \n",
      "                                                                                                  \n",
      " add_15 (Add)                   (None, 49, 64)       0           ['dropout_15[0][0]',             \n",
      "                                                                  'add_14[0][0]']                 \n",
      "                                                                                                  \n",
      " layer_normalization_16 (LayerN  (None, 49, 64)      128         ['add_15[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 3136)         0           ['layer_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_16 (Dropout)           (None, 3136)         0           ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense_17 (Dense)               (None, 2048)         6424576     ['dropout_16[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_17 (Dropout)           (None, 2048)         0           ['dense_17[0][0]']               \n",
      "                                                                                                  \n",
      " dense_18 (Dense)               (None, 1024)         2098176     ['dropout_17[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_18 (Dropout)           (None, 1024)         0           ['dense_18[0][0]']               \n",
      "                                                                                                  \n",
      " dense_19 (Dense)               (None, 5)            5125        ['dropout_18[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 9,393,420\n",
      "Trainable params: 9,393,413\n",
      "Non-trainable params: 7\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#def run_experiment(model):\n",
    "\n",
    "model = create_vit_classifier()\n",
    "\n",
    "\n",
    "optimizer = tfa.optimizers.AdamW(\n",
    "    learning_rate=learning_rate, weight_decay=weight_decay\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\n",
    "        keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n",
    "        keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "    # checkpoint_filepath = \"/tmp/checkpoint\"\n",
    "    # checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    #     checkpoint_filepath,\n",
    "    #     monitor=\"val_accuracy\",\n",
    "    #     save_best_only=True,\n",
    "    #     save_weights_only=True,\n",
    "    # )\n",
    "\n",
    "\n",
    "    # model.load_weights(checkpoint_filepath)\n",
    "    # _, accuracy, top_5_accuracy = model.evaluate(x_test, y_test)\n",
    "    # print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "    # print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n",
    "\n",
    "    # return history\n",
    "\n",
    "\n",
    "#history = run_experiment(vit_classifier)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e832f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step_size_train = np.ceil(train_generator.n/train_generator.batch_size)\n",
    "# step_size_val = np.ceil(val_generator.n/val_generator.batch_size)\n",
    "\n",
    "# history = model.fit(\n",
    "#     train_generator, steps_per_epoch=step_size_train, epochs=2, verbose=1,\\\n",
    "#     validation_data=val_generator, validation_steps=step_size_val,\\\n",
    "#     validation_freq=1#, class_weight=class_weights #class weights break everything and for some reaosn it thinks there are still 10 classes?\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9d56ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "2/2 [==============================] - 9s 1s/step - loss: 5.6797 - accuracy: 0.3088 - top-5-accuracy: 1.0000 - val_loss: 6.1702 - val_accuracy: 0.2101 - val_top-5-accuracy: 1.0000\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 237ms/step - loss: 7.5159 - accuracy: 0.3004 - top-5-accuracy: 1.0000 - val_loss: 6.5531 - val_accuracy: 0.2626 - val_top-5-accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "#batch_size = 100\n",
    "history = model.fit(\n",
    "        x=x_train,\n",
    "        y=y_train,\n",
    "        steps_per_epoch = np.ceil(len(y_train)/batch_size),\n",
    "        batch_size=batch_size,\n",
    "        epochs=2,\n",
    "        validation_data = (x_val, y_val),\n",
    "        validation_steps = np.ceil(len(y_val)/batch_size),\n",
    "        validation_freq=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2ab8143",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_Xtrain(X_train):\n",
    "    mn = []\n",
    "    mx = []\n",
    "    Xn_train = np.zeros(np.shape(X_train))\n",
    "    X_norm = np.zeros(np.shape(X_train))\n",
    "    for i in range(len(X_train[0, ::])):\n",
    "        mn.append(np.min(X_train[::, i]))\n",
    "        Xn_train[::, i] = X_train[::, i] - mn[i]\n",
    "    for i in range(len(X_train[0, ::])):\n",
    "        mx.append(np.max(Xn_train[::, i]))\n",
    "        if mx[i] == 0:\n",
    "            X_norm[::, i] = 0\n",
    "        if mx[i] != 0:\n",
    "            X_norm[::, i] = Xn_train[::, i]/mx[i]\n",
    "            \n",
    "    return X_norm, mx, mn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7c964dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "The accuracy of SqueezeNet is:  0.26260504201680673\n",
      "dict_keys(['loss', 'accuracy', 'top-5-accuracy', 'val_loss', 'val_accuracy', 'val_top-5-accuracy'])\n",
      "Model precision is:  0.052521008403361345\n",
      "Model f1_score is:  0.0831946755407654\n",
      "Model recall is:  0.2\n",
      "Model MSE is:  1.6365546218487395\n",
      "Confusion Matrix\n",
      "[[  0   0   0  16   0]\n",
      " [  0   0   0 100   0]\n",
      " [  0   0   0 220   0]\n",
      " [  0   0   0 125   0]\n",
      " [  0   0   0  15   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zacha\\anaconda3\\envs\\ML_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sklearn.metrics\n",
    "\n",
    "Y_test_hat=model.predict(x_test)\n",
    "y_test_hat=Y_test_hat.argmax(axis=-1)\n",
    "\n",
    "print(y_test_hat[:200])\n",
    "\n",
    "\n",
    "\n",
    "con_matrix = sklearn.metrics.confusion_matrix(y_test,y_test_hat)\n",
    "acc=np.diag(con_matrix).sum().astype(float)/con_matrix.sum()\n",
    "# acc = tensorflow.keras.metrics.Accuracy()\n",
    "# acc.reset_state()\n",
    "# acc.update_state(y_test, y_test_hat)\n",
    "\n",
    "\n",
    "print('The accuracy of SqueezeNet is: ', acc)\n",
    "\n",
    "min = np.min(con_matrix)\n",
    "max = np.max(con_matrix)\n",
    "temp_mat = con_matrix - min\n",
    "temp_mat = con_matrix/max\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(normalize_Xtrain(temp_mat)[0], cmap='gray')\n",
    "plt.title('Confusion Matrix for SqueezeNet')\n",
    "plt.xticks(list(range(len(['2', '3', '4', '5', '6']))), ['2', '3', '4', '5', '6'])\n",
    "plt.yticks(list(range(len(['2', '3', '4', '5', '6']))), ['2', '3', '4', '5', '6'])\n",
    "plt.ylabel('True Labels')\n",
    "plt.xlabel('Predicted Labels')\n",
    "\n",
    "print(history.history.keys())\n",
    "# plt.figure(figsize=(10,10))\n",
    "# plt.plot(np.arange(0, len(history.history['categorical_accuracy'])), history.history['categorical_accuracy'])\n",
    "# plt.plot(np.arange(0, len(history.history['val_categorical_accuracy'])), history.history['val_categorical_accuracy'])\n",
    "# plt.legend(('Training Accuracy', 'Validation Accuracy'))\n",
    "\n",
    "#Metrics\n",
    "precision = sklearn.metrics.precision_score(y_test,y_test_hat, average='macro')\n",
    "print('Model precision is: ', precision)\n",
    "\n",
    "f1_score = sklearn.metrics.f1_score(y_test,y_test_hat, average='macro')\n",
    "print('Model f1_score is: ', f1_score)\n",
    "\n",
    "recall = sklearn.metrics.recall_score(y_test,y_test_hat, average='macro')\n",
    "print('Model recall is: ', recall)\n",
    "\n",
    "MSE = sklearn.metrics.mean_squared_error(y_test,y_test_hat)\n",
    "print('Model MSE is: ', MSE)\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "print(con_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('ML_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "851288773b5edbc54f631fdf579cbc9e2fc2ac5bd43b2d347da3c29f51b44049"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
