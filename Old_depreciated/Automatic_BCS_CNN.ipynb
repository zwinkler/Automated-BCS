{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG Transfer Learning for Solar Flare Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from PIL import Image as pil_image\n",
    "import imageio\n",
    "import tensorflow\n",
    "import sklearn.metrics\n",
    "import itertools\n",
    "%matplotlib inline\n",
    "#plt.rcParams.update({'font.size': 32})\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_params(model):\n",
    "    total_params = 0 # initialize counter for total params\n",
    "    trainable_params = 0 # initialize counter for trainable params\n",
    "    print('Layer Name\\t\\tType\\t\\tFilter shape\\t\\t# Parameters\\tTrainable') # print column headings\n",
    "    for layer in model.layers: # loop over layers\n",
    "        lname = layer.name # grab layer name\n",
    "        ltype = type(layer).__name__ # grab layer type\n",
    "        ltype[ltype.find('/'):] # parse for only the last part of the string\n",
    "        if ltype=='Conv2D': # print for convolutional layers\n",
    "            weights = layer.get_weights()\n",
    "            print(lname+'\\t\\t'+ltype+'\\t\\t'+str(weights[0].shape)+'\\t\\t'+\\\n",
    "                  str(layer.count_params())+'\\t'+str(layer.trainable))\n",
    "            if layer.trainable:\n",
    "                trainable_params += layer.count_params()\n",
    "            total_params += layer.count_params() # update number of params\n",
    "        elif ltype=='MaxPooling2D': # print for max pool layers\n",
    "            weights = layer.get_weights()\n",
    "            print(lname+'\\t\\t'+ltype+'\\t---------------\\t\\t---')\n",
    "        elif ltype=='Flatten': # print for flatten layers\n",
    "            print(lname+'\\t\\t'+ltype+'\\t\\t---------------\\t\\t---')\n",
    "        elif ltype=='Dense': # print for dense layers\n",
    "            weights = layer.get_weights()\n",
    "            print(lname+'\\t\\t\\t'+ltype+'\\t\\t'+str(weights[0].shape)+'\\t\\t'+\\\n",
    "                  str(layer.count_params())+'\\t'+str(layer.trainable))\n",
    "            if layer.trainable:\n",
    "                trainable_params += layer.count_params()\n",
    "            total_params += layer.count_params() # update number of params\n",
    "        elif ltype=='Dropout': # print for dropout layers\n",
    "            print(lname+'\\t\\t'+ltype+'\\t\\t------------------\\t---')\n",
    "    print('---------------')\n",
    "    print('Total trainable parameters: '+str(trainable_params)) # print total params\n",
    "    print('Total untrainable parameters: '+str(total_params-trainable_params))\n",
    "    print('Total parameters: '+str(total_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_shapes(model):\n",
    "    print('Layer Name\\t\\tType\\t\\tInput Shape\\t\\tOutput Shape\\tTrainable')# print column headings\n",
    "    for layer in model.layers:  # loop over layers\n",
    "        lname = layer.name # grab layer name\n",
    "        ltype = type(layer).__name__ # grab layer type\n",
    "        ltype[ltype.find('/'):] # parse for only the last part of the string\n",
    "        if ltype=='Conv2D': # print for convolutional layers\n",
    "            print(lname+'\\t\\t'+ltype+'\\t\\t'+str(layer.input_shape)+'\\t'+\\\n",
    "                  str(layer.output_shape)+'\\t'+str(layer.trainable))\n",
    "        elif ltype=='MaxPooling2D': # print for maxpool layers\n",
    "            print(lname+'\\t\\t'+ltype+'\\t'+str(layer.input_shape)+'\\t'+\\\n",
    "                  str(layer.output_shape))\n",
    "        elif ltype=='Flatten': # print for flatten layers\n",
    "            print(lname+'\\t\\t'+ltype+'\\t\\t'+str(layer.input_shape)+'\\t'+\\\n",
    "                  str(layer.output_shape))\n",
    "        elif ltype=='Dense': # print for dense layers\n",
    "            print(lname+'\\t\\t\\t'+ltype+'\\t\\t'+str(layer.input_shape)+'\\t\\t'+\\\n",
    "                  str(layer.output_shape)+'\\t'+str(layer.trainable))\n",
    "        elif ltype=='Dropout': # print for dropout layers\n",
    "            print(lname+'\\t\\t'+ltype+'\\t\\t'+str(layer.input_shape)+'\\t'+\\\n",
    "                  str(layer.output_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import preprocess_input\n",
    "from astropy.io import fits\n",
    "import skimage.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Input\n",
    "import keras.applications\n",
    "input_tensor = Input(shape=(224,224,3))\n",
    "model1 = keras.applications.vgg16.VGG16(include_top=False,weights='imagenet',input_tensor=input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "new_output = model1.output # take the output as currently defined\n",
    "new_output = Flatten()(new_output)\n",
    "#new_output = Dropout(0.5)(new_output) #was commented out\n",
    "new_output = Dense(256,activation='relu')(new_output)\n",
    "#new_output = Dropout(0.5)(new_output)\n",
    "new_output = Dense(256,activation='relu')(new_output)\n",
    "new_output = Dropout(0.5)(new_output) #default is 0.5\n",
    "new_output = Dense(5,activation='softmax')(new_output) # this is for classification\n",
    "# new_output = Dense(1,activation='linear')(new_output) #this is for regression\n",
    "model2= Model(inputs=model1.input,outputs=new_output) # define a new model with the new output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer Name\t\tType\t\tFilter shape\t\t# Parameters\tTrainable\n",
      "block1_conv1\t\tConv2D\t\t(3, 3, 3, 64)\t\t1792\tTrue\n",
      "block1_conv2\t\tConv2D\t\t(3, 3, 64, 64)\t\t36928\tTrue\n",
      "block1_pool\t\tMaxPooling2D\t---------------\t\t---\n",
      "block2_conv1\t\tConv2D\t\t(3, 3, 64, 128)\t\t73856\tTrue\n",
      "block2_conv2\t\tConv2D\t\t(3, 3, 128, 128)\t\t147584\tTrue\n",
      "block2_pool\t\tMaxPooling2D\t---------------\t\t---\n",
      "block3_conv1\t\tConv2D\t\t(3, 3, 128, 256)\t\t295168\tTrue\n",
      "block3_conv2\t\tConv2D\t\t(3, 3, 256, 256)\t\t590080\tTrue\n",
      "block3_conv3\t\tConv2D\t\t(3, 3, 256, 256)\t\t590080\tTrue\n",
      "block3_pool\t\tMaxPooling2D\t---------------\t\t---\n",
      "block4_conv1\t\tConv2D\t\t(3, 3, 256, 512)\t\t1180160\tTrue\n",
      "block4_conv2\t\tConv2D\t\t(3, 3, 512, 512)\t\t2359808\tTrue\n",
      "block4_conv3\t\tConv2D\t\t(3, 3, 512, 512)\t\t2359808\tTrue\n",
      "block4_pool\t\tMaxPooling2D\t---------------\t\t---\n",
      "block5_conv1\t\tConv2D\t\t(3, 3, 512, 512)\t\t2359808\tTrue\n",
      "block5_conv2\t\tConv2D\t\t(3, 3, 512, 512)\t\t2359808\tTrue\n",
      "block5_conv3\t\tConv2D\t\t(3, 3, 512, 512)\t\t2359808\tTrue\n",
      "block5_pool\t\tMaxPooling2D\t---------------\t\t---\n",
      "flatten\t\tFlatten\t\t---------------\t\t---\n",
      "dense\t\t\tDense\t\t(25088, 256)\t\t6422784\tTrue\n",
      "dense_1\t\t\tDense\t\t(256, 256)\t\t65792\tTrue\n",
      "dropout\t\tDropout\t\t------------------\t---\n",
      "dense_2\t\t\tDense\t\t(256, 5)\t\t1285\tTrue\n",
      "---------------\n",
      "Total trainable parameters: 21204549\n",
      "Total untrainable parameters: 0\n",
      "Total parameters: 21204549\n"
     ]
    }
   ],
   "source": [
    "print_params(model2)\n",
    "#print(model2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model2.layers[:-6]:\n",
    "    layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer Name\t\tType\t\tFilter shape\t\t# Parameters\tTrainable\n",
      "block1_conv1\t\tConv2D\t\t(3, 3, 3, 64)\t\t1792\tFalse\n",
      "block1_conv2\t\tConv2D\t\t(3, 3, 64, 64)\t\t36928\tFalse\n",
      "block1_pool\t\tMaxPooling2D\t---------------\t\t---\n",
      "block2_conv1\t\tConv2D\t\t(3, 3, 64, 128)\t\t73856\tFalse\n",
      "block2_conv2\t\tConv2D\t\t(3, 3, 128, 128)\t\t147584\tFalse\n",
      "block2_pool\t\tMaxPooling2D\t---------------\t\t---\n",
      "block3_conv1\t\tConv2D\t\t(3, 3, 128, 256)\t\t295168\tFalse\n",
      "block3_conv2\t\tConv2D\t\t(3, 3, 256, 256)\t\t590080\tFalse\n",
      "block3_conv3\t\tConv2D\t\t(3, 3, 256, 256)\t\t590080\tFalse\n",
      "block3_pool\t\tMaxPooling2D\t---------------\t\t---\n",
      "block4_conv1\t\tConv2D\t\t(3, 3, 256, 512)\t\t1180160\tFalse\n",
      "block4_conv2\t\tConv2D\t\t(3, 3, 512, 512)\t\t2359808\tFalse\n",
      "block4_conv3\t\tConv2D\t\t(3, 3, 512, 512)\t\t2359808\tFalse\n",
      "block4_pool\t\tMaxPooling2D\t---------------\t\t---\n",
      "block5_conv1\t\tConv2D\t\t(3, 3, 512, 512)\t\t2359808\tFalse\n",
      "block5_conv2\t\tConv2D\t\t(3, 3, 512, 512)\t\t2359808\tFalse\n",
      "block5_conv3\t\tConv2D\t\t(3, 3, 512, 512)\t\t2359808\tFalse\n",
      "block5_pool\t\tMaxPooling2D\t---------------\t\t---\n",
      "flatten\t\tFlatten\t\t---------------\t\t---\n",
      "dense\t\t\tDense\t\t(25088, 256)\t\t6422784\tTrue\n",
      "dense_1\t\t\tDense\t\t(256, 256)\t\t65792\tTrue\n",
      "dropout\t\tDropout\t\t------------------\t---\n",
      "dense_2\t\t\tDense\t\t(256, 5)\t\t1285\tTrue\n",
      "---------------\n",
      "Total trainable parameters: 6489861\n",
      "Total untrainable parameters: 14714688\n",
      "Total parameters: 21204549\n"
     ]
    }
   ],
   "source": [
    "print_params(model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Data Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approach taken from https://medium.com/analytics-vidhya/write-your-own-custom-data-generator-for-tensorflow-keras-1252b64e41c3\n",
    "\n",
    "From https://www.tensorflow.org/api_docs/python/tf/keras/utils/Sequence: \"Sequence are a safer way to do multiprocessing. This structure guarantees that the network will only train once on each sample per epoch which is not the case with generators.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "from astropy.io import fits\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import skimage.transform\n",
    "class FitsDataGen(Sequence):\n",
    "    # The input to the data generator will be the dataframe and which columns to use\n",
    "    def __init__(self, df, X_col, y_col,\n",
    "                 directory,\n",
    "                 batch_size,\n",
    "                 input_size=(224, 224, 3),\n",
    "                 target_size=None,\n",
    "                 bitdepth=None,\n",
    "                 shuffle=True):\n",
    "        \n",
    "        self.df = df.copy() # dataframe\n",
    "        self.X_col = X_col # column for X data (filename)\n",
    "        self.y_col = y_col # column for y data (class label)\n",
    "        self.directory = directory # base directory for data\n",
    "        self.batch_size = batch_size # batch size\n",
    "        self.input_size = input_size # size expected by network (224,224,3) for VGG\n",
    "        self.target_size = target_size # resized image for spatial res sims\n",
    "        self.bitdepth = bitdepth # quantized image for bitdepth sims\n",
    "        self.shuffle = shuffle # whether to shuffle batches\n",
    "        \n",
    "        self.n = len(self.df) # number of data points\n",
    "        self.nclasses = df[y_col].nunique() # number of classes\n",
    "            \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            self.df = self.df.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    def __get_input(self, path, directory, input_size, target_size, bitdepth):\n",
    "    \n",
    "        with fits.open(directory+path) as img: # read in fits image\n",
    "            img.verify('silentfix')\n",
    "            img = img[0].data\n",
    "            \n",
    "        #img = np.expand_dims(img,axis=2) # copy single channel to three to create rgb dimensioned image\n",
    "        #img = np.tile(img,(1,1,3))\n",
    "        \n",
    "        # scale to target_size\n",
    "        if target_size is not None:\n",
    "            img = skimage.transform.resize(img, (target_size[0],target_size[1]), order=1, mode='reflect',\\\n",
    "                                           clip=True, preserve_range=True, anti_aliasing=True)\n",
    "        \n",
    "        # scale to input_size (expected dimensions for input to network)\n",
    "        img = skimage.transform.resize(img, (input_size[0],input_size[1]), order=1, mode='reflect',\\\n",
    "                                       clip=True, preserve_range=True, anti_aliasing=True)\n",
    "        \n",
    "        # put bitdepth stuff here eventually\n",
    "        \n",
    "        # scale intensities to range [0,255] as expected by VGG preprocessing function\n",
    "        # can cheat a bit here and treat each channel the same since these are grayscale images\n",
    "        # img = img + 5978.7 # -5978.7 is minimum of entire magnetogram dataset\n",
    "        # img = img/(2*5978.7)*255 # +5978.7 is maximum of entire magnetogram dataset\n",
    "        # img[img<-2550] = -2550\n",
    "        # img = img + 2550 # -5978.7 is minimum of entire magnetogram dataset\n",
    "        # img = img/(5100)*255 # +5978.7 is maximum of entire magnetogram dataset\n",
    "        img = img/(3500)*255 #changed to 3500 because some pixels need clipping\n",
    "        img[img>255] = 255\n",
    "        \n",
    "        \n",
    "        \n",
    "        img = preprocess_input(img) # preprocess according to VGG expectations\n",
    "\n",
    "        return img\n",
    "    \n",
    "    \n",
    "    def __get_output(self, label, num_classes):\n",
    "        #print(label)\n",
    "        print(label, num_classes)\n",
    "        return tensorflow.keras.utils.to_categorical(label, num_classes=num_classes)\n",
    "    \n",
    "    def __get_data(self, batches):\n",
    "        # Generates data containing batch_size samples\n",
    "\n",
    "        path_batch = batches[self.X_col]\n",
    "        \n",
    "        label_batch = batches[self.y_col]\n",
    "\n",
    "        X_batch = np.asarray([self.__get_input(x, self.directory, self.input_size, self.target_size, self.bitdepth)\\\n",
    "                              for x in path_batch])\n",
    "\n",
    "        y_batch = np.asarray([self.__get_output(y, self.nclasses) for y in label_batch])\n",
    "        print(y_batch)\n",
    "        \n",
    "        return X_batch, y_batch\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        batches = self.df[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        X, y = self.__get_data(batches)        \n",
    "        return X, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n // self.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = pd.read_csv('train_data.csv',dtype=str)\n",
    "# val_df = pd.read_csv('val_data.csv',dtype=str)\n",
    "# test_df = pd.read_csv('test_data.csv',dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = train_df.sample(frac=1).reset_index(drop=True)\n",
    "# val_df = val_df.sample(frac=1).reset_index(drop=True)\n",
    "# test_df = test_df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_generator = FitsDataGen(train_df, X_col='filename', y_col='class', directory='',\\\n",
    "#                               batch_size=128, input_size=(224,224,3),\\\n",
    "#                            target_size=None, bitdepth=None, shuffle=True)\n",
    "# val_generator = FitsDataGen(val_df, X_col='filename', y_col='class', directory='',\\\n",
    "#                             batch_size=128, input_size=(224,224,3),\\\n",
    "#                            target_size=None, bitdepth=None, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train_df = pd.read_csv('classifier_VGG/Train_Data_by_AR_sr600x600.csv',dtype=str)\n",
    "# val_df = pd.read_csv('classifier_VGG/Validation_data_by_AR_sr600x600.csv',dtype=str)\n",
    "# test_df = pd.read_csv('classifier_VGG/Test_Data_by_AR_sr600x600.csv',dtype=str)\n",
    "\n",
    "train_df = pd.read_csv('train_data_DHE_ALL.csv',dtype=str)\n",
    "val_df = pd.read_csv('val_data_DHE_ALL.csv',dtype=str)\n",
    "test_df = pd.read_csv('test_data_DHE_ALL.csv',dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3741 validated image filenames belonging to 5 classes.\n",
      "Found 1068 validated image filenames belonging to 5 classes.\n",
      "Found 533 validated image filenames belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.vgg16 import decode_predictions\n",
    "\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "train_generator = train_datagen.flow_from_dataframe(dataframe=train_df,\\\n",
    "                                                    directory='',\\\n",
    "                                                    xcol='filename',y_col='class',\\\n",
    "                                                    target_size=(224,224), color_mode='rgb',\\\n",
    "                                                    batch_size=128, class_mode='categorical',\\\n",
    "                                                    shuffle=True) #RETURN TO TRUEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n",
    "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "val_generator = val_datagen.flow_from_dataframe(dataframe=val_df,\\\n",
    "                                                directory = '',\\\n",
    "                                                xcol='filename',ycol='class',\\\n",
    "                                                target_size=(224,224), color_mode='rgb',\\\n",
    "                                                batch_size=128, class_mode='categorical',\\\n",
    "                                                shuffle=True)\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "test_generator = test_datagen.flow_from_dataframe(dataframe=test_df,\\\n",
    "                                                directory = '',\\\n",
    "                                                xcol='filename',ycol='class',\\\n",
    "                                                target_size=(224,224), color_mode='rgb',\\\n",
    "                                                batch_size=128, class_mode='categorical',\\\n",
    "                                                shuffle=False) #SHOULD STAY FALSEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "# from keras.applications.vgg16 import preprocess_input\n",
    "# from keras.applications.vgg16 import decode_predictions\n",
    "# train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "# train_generator = train_datagen.flow_from_directory('BCS_sorted_HDV\\\\',\\\n",
    "#                                                     target_size=(224,224), color_mode='rgb',\\\n",
    "#                                                     batch_size=128, class_mode='categorical',\\\n",
    "#                                                     shuffle=True)\n",
    "# val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "# val_generator = val_datagen.flow_from_directory('BCS_sorted_HDV\\\\',\\\n",
    "#                                                     target_size=(224,224), color_mode='rgb',\\\n",
    "#                                                     batch_size=128, class_mode='categorical',\\\n",
    "#                                                     shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_tnr(y_true,y_pred):\n",
    "    import keras.backend as K\n",
    "    y_true = K.argmax(y_true)\n",
    "    y_pred = K.argmax(y_pred)\n",
    "    neg_y_true = 1 - y_true\n",
    "    neg_y_pred = 1 - y_pred\n",
    "    fp = K.cast(K.sum(neg_y_true * y_pred),'float32')\n",
    "    tn = K.cast(K.sum(neg_y_true * neg_y_pred),'float32')\n",
    "    tnr = tn / (tn + fp + K.epsilon())\n",
    "    return tnr\n",
    "\n",
    "def categorical_tpr(y_true,y_pred):\n",
    "    import keras.backend as K\n",
    "    y_true = K.argmax(y_true)\n",
    "    y_pred = K.argmax(y_pred)\n",
    "    neg_y_pred = 1 - y_pred\n",
    "    fn = K.cast(K.sum(y_true * neg_y_pred),'float32')\n",
    "    tp = K.cast(K.sum(y_true * y_pred),'float32')\n",
    "    tpr = tp / (tp + fn + K.epsilon())\n",
    "    return tpr\n",
    "\n",
    "def categorical_tss(y_true,y_pred):\n",
    "    import keras.backend as K\n",
    "    tpr = categorical_tpr(y_true,y_pred)\n",
    "    tnr = categorical_tnr(y_true,y_pred)\n",
    "    tss = tpr + tnr - 1\n",
    "    return tss\n",
    "\n",
    "def save_con_mat(y_true, y_pred):\n",
    "    import tensorflow as tf\n",
    "    print((y_true.shape))\n",
    "    print((y_pred.shape))\n",
    "    con_matrix = tf.math.confusion_matrix(y_true, y_pred)\n",
    "    # acc=np.diag(con_matrix).sum().astype(float)/con_matrix.sum()\n",
    "    return con_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "adam_opt = Adam(learning_rate=0.001)\n",
    "model2.compile(loss='categorical_crossentropy', optimizer=adam_opt,\\\n",
    "               metrics=['categorical_accuracy'])# save_con_mat]) #,categorical_tnr,categorical_tpr,categorical_tss])\n",
    "#for classification\n",
    "\n",
    "# model2.compile(loss='mean_absolute_percentage_error', optimizer=adam_opt,\\\n",
    "#                metrics=['categorical_accuracy'])# save_con_mat]) #,categorical_tnr,categorical_tpr,categorical_tss])\n",
    "#                # for regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.0\n",
      "Batch size:  128\n",
      "9.0\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "filepath = 'BCS_CNN\\\\BCS_CNN.hdf5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_categorical_tss', verbose=1, save_best_only=False, mode='max')\n",
    "early_stop = EarlyStopping(monitor='val_categorical_tss', min_delta=0.001, patience=5, verbose=1, mode='max')\n",
    "#callbacks_list = [checkpoint, early_stop]\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "step_size_train = np.ceil(train_generator.n/train_generator.batch_size)\n",
    "print(step_size_train)\n",
    "print('Batch size: ', train_generator.batch_size)\n",
    "#step_size_train = 2373 # to help debug val accuracy issue\n",
    "step_size_val = np.ceil(val_generator.n/val_generator.batch_size)\n",
    "print(step_size_val)\n",
    "#step_size_val = 303 # to help debug val accuracy issue\n",
    "\n",
    "# the following assumes that 0 is the majority class\n",
    "# class_weights = {0: 1.,\n",
    "#                  1: (np.asarray(train_generator.classes)==0).sum()/(np.asarray(train_generator.classes)==1).sum()}\n",
    "# the following taken from https://www.tensorflow.org/tutorials/structured_data/imbalanced_data\n",
    "#class_weights = {0: (1/(train_generator.classes==0).sum())*len(train_generator.classes)/2,\n",
    "#                 1: (1/(train_generator.classes==1).sum())*len(train_generator.classes)/2}\n",
    "# class_weights = {0: 1.,\n",
    "#                 1: 6.}\n",
    "\n",
    "from sklearn.utils import class_weight \n",
    "class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(train_df['class']), y =train_df['class'])\n",
    "class_weights = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1.425142857142857, 1: 1.4388461538461539, 2: 0.4241496598639456, 3: 0.9091130012150668, 4: 6.864220183486238}\n"
     ]
    }
   ],
   "source": [
    "print(class_weights)\n",
    "# class_weights[0] = 2\n",
    "# class_weights[1] = 1.5\n",
    "# class_weights[2] = 0.2\n",
    "# class_weights[3] = 1.3\n",
    "# class_weights[4] = 7\n",
    "# print(class_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30/30 [==============================] - ETA: 0s - loss: 1.5289 - categorical_accuracy: 0.6792\n",
      "Epoch 00001: saving model to BCS_CNN\\BCS_CNN.hdf5\n",
      "30/30 [==============================] - 13s 425ms/step - loss: 1.5289 - categorical_accuracy: 0.6792 - val_loss: 0.7094 - val_categorical_accuracy: 0.8577\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.8235 - categorical_accuracy: 0.7934\n",
      "Epoch 00002: saving model to BCS_CNN\\BCS_CNN.hdf5\n",
      "30/30 [==============================] - 12s 384ms/step - loss: 0.8235 - categorical_accuracy: 0.7934 - val_loss: 0.5815 - val_categorical_accuracy: 0.8221\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-fc46f5c9dfba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m history = model2.fit(train_generator, steps_per_epoch=step_size_train, epochs=10, verbose=1,\\\n\u001b[0m\u001b[0;32m      2\u001b[0m                      \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep_size_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                      validation_freq=1, class_weight=class_weights)\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML_env\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1214\u001b[0m                 _r=1):\n\u001b[0;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1217\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML_env\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML_env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 910\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML_env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    940\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 942\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    943\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML_env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3128\u001b[0m       (graph_function,\n\u001b[0;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3130\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML_env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1958\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1959\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML_env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML_env\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model2.fit(train_generator, steps_per_epoch=step_size_train, epochs=10, verbose=1,\\\n",
    "                     callbacks=callbacks_list, validation_data=val_generator, validation_steps=step_size_val,\\\n",
    "                     validation_freq=1, class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 block1_conv1/kernel:0\n",
      "1 block1_conv1/bias:0\n",
      "2 block1_conv2/kernel:0\n",
      "3 block1_conv2/bias:0\n",
      "4 block2_conv1/kernel:0\n",
      "5 block2_conv1/bias:0\n",
      "6 block2_conv2/kernel:0\n",
      "7 block2_conv2/bias:0\n",
      "8 block3_conv1/kernel:0\n",
      "9 block3_conv1/bias:0\n",
      "10 block3_conv2/kernel:0\n",
      "11 block3_conv2/bias:0\n",
      "12 block3_conv3/kernel:0\n",
      "13 block3_conv3/bias:0\n",
      "14 block4_conv1/kernel:0\n",
      "15 block4_conv1/bias:0\n",
      "16 block4_conv2/kernel:0\n",
      "17 block4_conv2/bias:0\n",
      "18 block4_conv3/kernel:0\n",
      "19 block4_conv3/bias:0\n",
      "20 block5_conv1/kernel:0\n",
      "21 block5_conv1/bias:0\n",
      "22 block5_conv2/kernel:0\n",
      "23 block5_conv2/bias:0\n",
      "24 block5_conv3/kernel:0\n",
      "25 block5_conv3/bias:0\n",
      "26 dense/kernel:0\n",
      "27 dense/bias:0\n",
      "28 dense_1/kernel:0\n",
      "29 dense_1/bias:0\n",
      "30 dense_2/kernel:0\n",
      "31 dense_2/bias:0\n"
     ]
    }
   ],
   "source": [
    "for i, w in enumerate(model2.weights): print(i, w.name)\n",
    "model2.save('BCS_CNN\\\\test.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_Xtrain(X_train):\n",
    "    mn = []\n",
    "    mx = []\n",
    "    Xn_train = np.zeros(np.shape(X_train))\n",
    "    X_norm = np.zeros(np.shape(X_train))\n",
    "    for i in range(len(X_train[0, ::])):\n",
    "        mn.append(np.min(X_train[::, i]))\n",
    "        Xn_train[::, i] = X_train[::, i] - mn[i]\n",
    "    for i in range(len(X_train[0, ::])):\n",
    "        mx.append(np.max(Xn_train[::, i]))\n",
    "        if mx[i] == 0:\n",
    "            X_norm[::, i] = 0\n",
    "        if mx[i] != 0:\n",
    "            X_norm[::, i] = Xn_train[::, i]/mx[i]\n",
    "            \n",
    "    return X_norm, mx, mn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 5 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2\n",
      " 2 4 3 4 3 3 4 3 4 3 3 3 5 3 3 2 3 4 3 3 3 3 3 3 3 3 3 3 4 3 4 3 3 3 5 3 3\n",
      " 3 3 3 3 3 3 3 3 3 4 3 3 3 5 3 3 6 4 3 4 2 3 4 4 6 3 3 3 4 3 3 3 4 3 4 3 3\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 3 2 4 4 4 4 4 4 6 4 4 4 3 4 2 4 3 4 4 4 4\n",
      " 4 4 4 4 5 2 4 4 4 4 5 4 4 4 4]\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]\n",
      "The accuracy of SqueezeNet is:  0.799249530956848\n",
      "dict_keys(['loss', 'categorical_accuracy', 'val_loss', 'val_categorical_accuracy'])\n",
      "Model precision is:  0.7330343357394533\n",
      "Model f1_score is:  0.7660452701693099\n",
      "Model recall is:  0.8202847242847243\n",
      "Model MSE is:  0.4821763602251407\n",
      "Confusion Matrix\n",
      "[[ 71   3   0   1   0]\n",
      " [  2  51  16   3   2]\n",
      " [ 12  19 194  18   9]\n",
      " [  3   4  12  97   1]\n",
      " [  1   0   1   0  13]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sklearn.metrics\n",
    "\n",
    "Y_test_hat=model2.predict(test_generator)\n",
    "y_test_hat=Y_test_hat.argmax(axis=-1)+2\n",
    "\n",
    "print(y_test_hat[:200])\n",
    "\n",
    "\n",
    "y_test = test_df['class']\n",
    "y_test = [int(i) for i in y_test]\n",
    "print(y_test[:200])\n",
    "\n",
    "con_matrix = sklearn.metrics.confusion_matrix(y_test,y_test_hat)\n",
    "acc=np.diag(con_matrix).sum().astype(float)/con_matrix.sum()\n",
    "# acc = tensorflow.keras.metrics.Accuracy()\n",
    "# acc.reset_state()\n",
    "# acc.update_state(y_test, y_test_hat)\n",
    "\n",
    "\n",
    "print('The accuracy of SqueezeNet is: ', acc)\n",
    "\n",
    "min = np.min(con_matrix)\n",
    "max = np.max(con_matrix)\n",
    "temp_mat = con_matrix - min\n",
    "temp_mat = con_matrix/max\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(normalize_Xtrain(con_matrix)[0], cmap='gray')\n",
    "plt.title('Confusion Matrix for VGG16')\n",
    "plt.xticks(list(range(len(['2', '3', '4', '5', '6']))), ['2', '3', '4', '5', '6'])\n",
    "plt.yticks(list(range(len(['2', '3', '4', '5', '6']))), ['2', '3', '4', '5', '6'])\n",
    "plt.ylabel('True Labels')\n",
    "plt.xlabel('Predicted Labels')\n",
    "\n",
    "print(history.history.keys())\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(np.arange(0, len(history.history['categorical_accuracy'])), history.history['categorical_accuracy'])\n",
    "plt.plot(np.arange(0, len(history.history['val_categorical_accuracy'])), history.history['val_categorical_accuracy'])\n",
    "plt.legend(('Training Accuracy', 'Validation Accuracy'))\n",
    "\n",
    "#Metrics\n",
    "precision = sklearn.metrics.precision_score(y_test,y_test_hat, average='macro')\n",
    "print('Model precision is: ', precision)\n",
    "\n",
    "f1_score = sklearn.metrics.f1_score(y_test,y_test_hat, average='macro')\n",
    "print('Model f1_score is: ', f1_score)\n",
    "\n",
    "recall = sklearn.metrics.recall_score(y_test,y_test_hat, average='macro')\n",
    "print('Model recall is: ', recall)\n",
    "\n",
    "MSE = sklearn.metrics.mean_squared_error(y_test,y_test_hat)\n",
    "print('Model MSE is: ', MSE)\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "print(con_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 5, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 3, 3, 6, 3, 3, 3, 3, 3, 3, 3, 6, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 6, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 6, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 6, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 6, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 6, 4, 4, 4, 2, 6, 4, 4, 4, 6, 4, 4, 4, 4, 4, 4, 4, 6, 4, 4, 6, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 3, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 4, 6, 2, 6, 6, 6, 6, 6]\n",
      "<class 'int'>\n",
      "<class 'int'>\n",
      "The accuracy of the network model2 is:  0.9324577861163227\n",
      "dict_keys(['loss', 'categorical_accuracy', 'val_loss', 'val_categorical_accuracy'])\n",
      "Model unweighted precision is:  0.8539392608430223\n",
      "Model weighted precision is:  0.9447380902282781\n",
      "\n",
      "Model unweighted recall is:  0.9285206745206747\n",
      "Model weighted recall is:  0.9324577861163227\n",
      "\n",
      "Model unweighted f1_score is:  0.8818676561533705\n",
      "Model weighted f1_score is:  0.9356775628552632\n",
      "\n",
      "Confusion Matrix\n",
      "[[ 74   0   0   1   0]\n",
      " [  0  69   0   3   2]\n",
      " [ 12   0 231   0   9]\n",
      " [  3   4   0 110   0]\n",
      " [  1   0   1   0  13]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_within_1 = []\n",
    "for i in range(0, len(y_test)):\n",
    "    if ((y_test_hat[i] == y_test[i]+1) or (y_test_hat[i] == y_test[i]-1) or (y_test_hat[i] == y_test[i])):\n",
    "        y_within_1.append(y_test[i])\n",
    "    else:\n",
    "        y_within_1.append(y_test_hat[i])\n",
    "\n",
    "print(y_within_1)\n",
    "print(type(y_within_1[20]))\n",
    "print(type(y_test[0]))\n",
    "\n",
    "con_matrix = sklearn.metrics.confusion_matrix(y_test,y_within_1)\n",
    "acc=np.diag(con_matrix).sum().astype(float)/con_matrix.sum()\n",
    "\n",
    "\n",
    "print('The accuracy of the network model2 is: ', acc)\n",
    "\n",
    "min = np.min(con_matrix)\n",
    "max = np.max(con_matrix)\n",
    "temp_mat = con_matrix - min\n",
    "temp_mat = con_matrix/max\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(normalize_Xtrain(con_matrix)[0], cmap='gray')\n",
    "plt.title('Confusion Matrix for VGG16')\n",
    "plt.xticks(list(range(len(['2', '3', '4', '5', '6']))), ['2', '3', '4', '5', '6'])\n",
    "plt.yticks(list(range(len(['2', '3', '4', '5', '6']))), ['2', '3', '4', '5', '6'])\n",
    "plt.ylabel('True Labels')\n",
    "plt.xlabel('Predicted Labels')\n",
    "\n",
    "\n",
    "print(history.history.keys())\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(np.arange(0, len(history.history['categorical_accuracy'])), history.history['categorical_accuracy'])\n",
    "plt.plot(np.arange(0, len(history.history['val_categorical_accuracy'])), history.history['val_categorical_accuracy'])\n",
    "plt.legend(('Training Accuracy', 'Validation Accuracy'))\n",
    "\n",
    "#Metrics\n",
    "precision = sklearn.metrics.precision_score(y_test,y_within_1, average='macro')\n",
    "print('Model unweighted precision is: ', precision)\n",
    "precision = sklearn.metrics.precision_score(y_test,y_within_1, average='weighted')\n",
    "print('Model weighted precision is: ', precision)\n",
    "print()\n",
    "\n",
    "#print('Avg :', sklearn.metrics.accuracy_score(y_test, y_test_hat, normalize=False))\n",
    "\n",
    "recall = sklearn.metrics.recall_score(y_test,y_within_1, average='macro')\n",
    "print('Model unweighted recall is: ', recall)\n",
    "recall = sklearn.metrics.recall_score(y_test,y_within_1, average='weighted')\n",
    "print('Model weighted recall is: ', recall)\n",
    "print()\n",
    "\n",
    "f1_score = sklearn.metrics.f1_score(y_test,y_within_1, average='macro')\n",
    "print('Model unweighted f1_score is: ', f1_score)\n",
    "f1_score = sklearn.metrics.f1_score(y_test,y_within_1, average='weighted')\n",
    "print('Model weighted f1_score is: ', f1_score)\n",
    "print()\n",
    "\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "print(con_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# model2.fit(train_generator, steps_per_epoch=step_size_train, epochs=10, verbose=1,\\\n",
    "#                      callbacks=callbacks_list, validation_data=val_generator, validation_steps=step_size_val,\\\n",
    "#                      validation_freq=1, class_weight=class_weights, max_queue_size=100, workers=20, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# model2.fit(ImageDataGenerator, steps_per_epoch=step_size_train, epochs=10, verbose=1,\\\n",
    "#                      callbacks=callbacks_list, validation_data=val_generator, validation_steps=step_size_val,\\\n",
    "#                      validation_freq=1, class_weight=class_weights,\\\n",
    "#                      max_queue_size=100, workers=16, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(model2.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import load_model\n",
    "# model2 = load_model('model.best.hdf5', custom_objects={'categorical_tnr': categorical_tnr,\\\n",
    "#                                                        'categorical_tpr': categorical_tpr,\\\n",
    "#                                                        'categorical_tss': categorical_tss})\n",
    "# model2.compile(loss='categorical_crossentropy', optimizer=adam_opt,\\\n",
    "#                metrics=['categorical_accuracy',categorical_tnr,categorical_tpr,categorical_tss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "# from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "# test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "# test_generator = test_datagen.flow_from_directory('VGG_AR_Dataset/TestSet_224',\\\n",
    "#                                                 target_size=(224,224), color_mode='rgb',\\\n",
    "#                                                 batch_size=128, class_mode='categorical',\\\n",
    "#                                                 shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model2.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(model2.evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(test_generator.labels==0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(test_generator.labels==1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
